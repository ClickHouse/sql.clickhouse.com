{
	"queries": [
	  {
		"id": "12EBW5JKMBVOKUUANQPR1M",
		"name": "Disk space usage",
		"group": "amazon_reviews",
		"comment": "",
		"query": "SELECT\n    disk_name,\n    formatReadableSize(sum(data_compressed_bytes) AS size) AS compressed,\n    formatReadableSize(sum(data_uncompressed_bytes) AS usize) AS uncompressed,\n    round(usize / size, 2) AS compr_rate,\n    sum(rows) AS rows,\n    count() AS part_count\nFROM system.parts\nWHERE (active = 1) AND (table = 'amazon_reviews')\nGROUP BY disk_name\nORDER BY size DESC;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BWOLVGMCMNCC3JDWF8EQGB",
		"name": "Top 10 most-helpful reviews",
		"group": "amazon_reviews",
		"comment": "",
		"query": "SELECT\n    product_title,\n    review_headline\nFROM amazon.amazon_reviews\nORDER BY helpful_votes DESC\nLIMIT 10;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "2DSBPSYXKLHRWNWMDPSUJN",
		"name": "Top 10 products with most reviews",
		"group": "amazon_reviews",
		"comment": "",
		"query": "SELECT\n    any(product_title),\n    count()\nFROM amazon.amazon_reviews\nGROUP BY product_id\nORDER BY 2 DESC\nLIMIT 10;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "OJJIEGD4NZK6KWH8FHYD64",
		"name": "Avg review ratings per month per product",
		"group": "amazon_reviews",
		"comment": "",
		"query": "SELECT\n    toStartOfMonth(review_date) AS month,\n    any(product_title),\n    avg(star_rating) AS avg_stars\nFROM amazon.amazon_reviews\nGROUP BY\n    month,\n    product_id\nORDER BY\n    month DESC,\n    product_id ASC\nLIMIT 20;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "C8VZQAGWJKHVQFFTRB2R7B",
		"name": "Total number of votes per product category",
		"group": "amazon_reviews",
		"comment": "",
		"query": "SELECT\n    sum(total_votes),\n    product_category\nFROM amazon.amazon_reviews\nGROUP BY product_category\nORDER BY 1 DESC\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "AT61M2PNSTBFNVKESBTJWE",
		"name": "Find products with 'awful' in reviews",
		"group": "amazon_reviews",
		"comment": "",
		"query": "SELECT\n    product_id,\n    any(product_title),\n    avg(star_rating),\n    count() AS count\nFROM amazon.amazon_reviews\nWHERE position(review_body, 'awful') > 0\nGROUP BY product_id\nORDER BY count DESC\nLIMIT 50;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "VWSFKKJTECSIDPHNCYE5BP",
		"name": "Find products with 'awesome' in reviews",
		"group": "amazon_reviews",
		"comment": "",
		"query": "SELECT\n    product_id,\n    any(product_title),\n    avg(star_rating),\n    count() AS count\nFROM amazon.amazon_reviews\nWHERE position(review_body, 'awesome') > 0\nGROUP BY product_id\nORDER BY count DESC\nLIMIT 50;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GEOICKHUJBUXMYROUXJK7C",
		"name": "CPU/network utilization per web server",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q1.1: What is the CPU/network utilization for each web server since midnight?\n\nSELECT machine_name,\n       MIN(cpu) AS cpu_min,\n       MAX(cpu) AS cpu_max,\n       AVG(cpu) AS cpu_avg,\n       MIN(net_in) AS net_in_min,\n       MAX(net_in) AS net_in_max,\n       AVG(net_in) AS net_in_avg,\n       MIN(net_out) AS net_out_min,\n       MAX(net_out) AS net_out_max,\n       AVG(net_out) AS net_out_avg\nFROM (\n  SELECT machine_name,\n         COALESCE(cpu_user, 0.0) AS cpu,\n         COALESCE(bytes_in, 0.0) AS net_in,\n         COALESCE(bytes_out, 0.0) AS net_out\n  FROM mgbench.logs1\n  WHERE machine_name IN ('anansi','aragog','urd')\n    AND log_time >= TIMESTAMP '2017-01-11 00:00:00'\n) AS r\nGROUP BY machine_name;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "FKYNODO5J9SFHP9K7VXJAZ",
		"name": "Machine offline in the past day",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q1.2: Which computer lab machines have been offline in the past day?\n\nSELECT machine_name,\n       log_time\nFROM mgbench.logs1\nWHERE (machine_name LIKE 'cslab%' OR\n       machine_name LIKE 'mslab%')\n  AND load_one IS NULL\n  AND log_time >= TIMESTAMP '2017-01-10 00:00:00'\nORDER BY machine_name,\n         log_time;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "EVVZPZ2K5VDLHJ69SNJH1L",
		"name": "Hourly average metrics for specific workstation last 10 days",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q1.3: What are the hourly average metrics during the past 10 days for a specific workstation?\n\nSELECT dt,\n       hr,\n       AVG(load_fifteen) AS load_fifteen_avg,\n       AVG(load_five) AS load_five_avg,\n       AVG(load_one) AS load_one_avg,\n       AVG(mem_free) AS mem_free_avg,\n       AVG(swap_free) AS swap_free_avg\nFROM (\n  SELECT CAST(log_time AS DATE) AS dt,\n         EXTRACT(HOUR FROM log_time) AS hr,\n         load_fifteen,\n         load_five,\n         load_one,\n         mem_free,\n         swap_free\n  FROM mgbench.logs1\n  WHERE machine_name = 'babbage'\n    AND load_fifteen IS NOT NULL\n    AND load_five IS NOT NULL\n    AND load_one IS NOT NULL\n    AND mem_free IS NOT NULL\n    AND swap_free IS NOT NULL\n    AND log_time >= TIMESTAMP '2017-01-01 00:00:00'\n) AS r\nGROUP BY dt,\n         hr\nORDER BY dt,\n         hr;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JMQOG4IV5ADD46Y6QBG4AO",
		"name": "Server blocked on disk I/O",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q1.4: Over 1 month, how often was each server blocked on disk I/O?\n\nSELECT machine_name,\n       COUNT(*) AS spikes\nFROM mgbench.logs1\nWHERE machine_group = 'Servers'\n  AND cpu_wio > 0.99\n  AND log_time >= TIMESTAMP '2016-12-01 00:00:00'\n  AND log_time < TIMESTAMP '2017-01-01 00:00:00'\nGROUP BY machine_name\nORDER BY spikes DESC\nLIMIT 10;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JJQ4TZJTB6HGD8YLEHPRCE",
		"name": "Low memory external VMs",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q1.5: Which externally reachable VMs have run low on memory?\n\nSELECT machine_name,\n       dt,\n       MIN(mem_free) AS mem_free_min\nFROM (\n  SELECT machine_name,\n         CAST(log_time AS DATE) AS dt,\n         mem_free\n  FROM mgbench.logs1\n  WHERE machine_group = 'DMZ'\n    AND mem_free IS NOT NULL\n) AS r\nGROUP BY machine_name,\n         dt\nHAVING MIN(mem_free) < 10000\nORDER BY machine_name,\n         dt;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "POIZV5NWCQXZ7P7CYNQFYD",
		"name": "Total hourly network traffic",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q1.6: What is the total hourly network traffic across all file servers?\n\nSELECT dt,\n       hr,\n       SUM(net_in) AS net_in_sum,\n       SUM(net_out) AS net_out_sum,\n       SUM(net_in) + SUM(net_out) AS both_sum\nFROM (\n  SELECT CAST(log_time AS DATE) AS dt,\n         EXTRACT(HOUR FROM log_time) AS hr,\n         COALESCE(bytes_in, 0.0) / 1000000000.0 AS net_in,\n         COALESCE(bytes_out, 0.0) / 1000000000.0 AS net_out\n  FROM mgbench.logs1\n  WHERE machine_name IN ('allsorts','andes','bigred','blackjack','bonbon',\n      'cadbury','chiclets','cotton','crows','dove','fireball','hearts','huey',\n      'lindt','milkduds','milkyway','mnm','necco','nerds','orbit','peeps',\n      'poprocks','razzles','runts','smarties','smuggler','spree','stride',\n      'tootsie','trident','wrigley','york')\n) AS r\nGROUP BY dt,\n         hr\nORDER BY both_sum DESC\nLIMIT 10;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "W82SBNYFW4KENKMAJ1S9T1",
		"name": "Requests cause server errors past 2 weeks",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q2.1: Which requests have caused server errors within the past 2 weeks?\n\nSELECT *\nFROM mgbench.logs2\nWHERE status_code >= 500\n  AND log_time >= TIMESTAMP '2012-12-18 00:00:00'\nORDER BY log_time;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "T97TB1WVEF3V6WV1WTQSAX",
		"name": "Detect user password file leak",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q2.2: During a specific 2-week period, was the user password file leaked?\n\nSELECT *\nFROM mgbench.logs2\nWHERE status_code >= 200\n  AND status_code < 300\n  AND request LIKE '%/etc/passwd%'\n  AND log_time >= TIMESTAMP '2012-05-06 00:00:00'\n  AND log_time < TIMESTAMP '2012-05-20 00:00:00';",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "F7QHSLYQGCGZDU1VFXKRMP",
		"name": "Avg path depth for top-level requests in the past month",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q2.3: What was the average path depth for top-level requests in the past month?\n\nSELECT top_level,\n       AVG(LENGTH(request) - LENGTH(REPLACE(request, '/', ''))) AS depth_avg\nFROM (\n  SELECT SUBSTRING(request FROM 1 FOR len) AS top_level,\n         request\n  FROM (\n    SELECT POSITION(SUBSTRING(request FROM 2), '/') AS len,\n           request\n    FROM mgbench.logs2\n    WHERE status_code >= 200\n      AND status_code < 300\n      AND log_time >= TIMESTAMP '2012-12-01 00:00:00'\n  ) AS r\n  WHERE len > 0\n) AS s\nWHERE top_level IN ('/about','/courses','/degrees','/events',\n                    '/grad','/industry','/news','/people',\n                    '/publications','/research','/teaching','/ugrad')\nGROUP BY top_level\nORDER BY top_level;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "T25HUSKE3NRV5VFCNMVXAD",
		"name": "Detect clients with excessive number of requests",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q2.4: During the last 3 months, which clients have made an excessive number of requests?\n\nSELECT client_ip,\n       COUNT(*) AS num_requests\nFROM mgbench.logs2\nWHERE log_time >= TIMESTAMP '2012-10-01 00:00:00'\nGROUP BY client_ip\nHAVING COUNT(*) >= 100000\nORDER BY num_requests DESC;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "UTDAJTYXHW9CJSAIA1LXOU",
		"name": "Daily unique visitors",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q2.5: What are the daily unique visitors?\n\nSELECT dt,\n       COUNT(DISTINCT client_ip)\nFROM (\n  SELECT CAST(log_time AS DATE) AS dt,\n         client_ip\n  FROM mgbench.logs2\n) AS r\nGROUP BY dt\nORDER BY dt;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "XUZAXVAMUELHY3JKXZJ57X",
		"name": "Avg and max data transfer rates",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q2.6: What are the average and maximum data transfer rates (Gbps)?\n\nSELECT AVG(transfer) / 125000000.0 AS transfer_avg,\n       MAX(transfer) / 125000000.0 AS transfer_max\nFROM (\n  SELECT log_time,\n         SUM(object_size) AS transfer\n  FROM mgbench.logs2\n  GROUP BY log_time\n) AS r;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "8NYJBXCD4FEHS1UMGQVI9G",
		"name": "Detect freezing indoor temperature",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q3.1: Did the indoor temperature reach freezing over the weekend?\n\nSELECT *\nFROM mgbench.logs3\nWHERE event_type = 'temperature'\n  AND event_value <= 32.0\n  AND log_time >= '2019-11-29 17:00:00.000';",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "ARQ8M5MAJQAGWL2S5QKMVD",
		"name": "Last 6 months number of door openings",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q3.4: Over the past 6 months, how frequently were each door opened?\n\nSELECT device_name,\n       device_floor,\n       COUNT(*) AS ct\nFROM mgbench.logs3\nWHERE event_type = 'door_open'\n  AND log_time >= '2019-06-01 00:00:00.000'\nGROUP BY device_name,\n         device_floor\nORDER BY ct DESC;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "WAMYYT2EUF2J9LEXVZ2HQW",
		"name": "Find where temperature variations occur in winter and summer",
		"group": "mgbench",
		"comment": "",
		"query": "\n\n-- Q3.5: Where in the building do large temperature variations occur in winter and summer?\n\nWITH temperature AS (\n  SELECT dt,\n         device_name,\n         device_type,\n         device_floor\n  FROM (\n    SELECT dt,\n           hr,\n           device_name,\n           device_type,\n           device_floor,\n           AVG(event_value) AS temperature_hourly_avg\n    FROM (\n      SELECT CAST(log_time AS DATE) AS dt,\n             EXTRACT(HOUR FROM log_time) AS hr,\n             device_name,\n             device_type,\n             device_floor,\n             event_value\n      FROM mgbench.logs3\n      WHERE event_type = 'temperature'\n    ) AS r\n    GROUP BY dt,\n             hr,\n             device_name,\n             device_type,\n             device_floor\n  ) AS s\n  GROUP BY dt,\n           device_name,\n           device_type,\n           device_floor\n  HAVING MAX(temperature_hourly_avg) - MIN(temperature_hourly_avg) >= 25.0\n)\nSELECT DISTINCT device_name,\n       device_type,\n       device_floor,\n       'WINTER'\nFROM temperature\nWHERE dt >= DATE '2018-12-01'\n  AND dt < DATE '2019-03-01'\nUNION DISTINCT\nSELECT DISTINCT device_name,\n       device_type,\n       device_floor,\n       'SUMMER'\nFROM temperature\nWHERE dt >= DATE '2019-06-01'\n  AND dt < DATE '2019-09-01';",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "VQWGJ3Y4A5CBGWXEQBDEJL",
		"name": "Monthly power consumption metrics per device category",
		"group": "mgbench",
		"comment": "",
		"query": "-- Q3.6: For each device category, what are the monthly power consumption metrics?\n\nSELECT yr,\n       mo,\n       SUM(coffee_hourly_avg) AS coffee_monthly_sum,\n       AVG(coffee_hourly_avg) AS coffee_monthly_avg,\n       SUM(printer_hourly_avg) AS printer_monthly_sum,\n       AVG(printer_hourly_avg) AS printer_monthly_avg,\n       SUM(projector_hourly_avg) AS projector_monthly_sum,\n       AVG(projector_hourly_avg) AS projector_monthly_avg,\n       SUM(vending_hourly_avg) AS vending_monthly_sum,\n       AVG(vending_hourly_avg) AS vending_monthly_avg\nFROM (\n  SELECT dt,\n         yr,\n         mo,\n         hr,\n         AVG(coffee) AS coffee_hourly_avg,\n         AVG(printer) AS printer_hourly_avg,\n         AVG(projector) AS projector_hourly_avg,\n         AVG(vending) AS vending_hourly_avg\n  FROM (\n    SELECT CAST(log_time AS DATE) AS dt,\n           EXTRACT(YEAR FROM log_time) AS yr,\n           EXTRACT(MONTH FROM log_time) AS mo,\n           EXTRACT(HOUR FROM log_time) AS hr,\n           CASE WHEN device_name LIKE 'coffee%' THEN event_value END AS coffee,\n           CASE WHEN device_name LIKE 'printer%' THEN event_value END AS printer,\n           CASE WHEN device_name LIKE 'projector%' THEN event_value END AS projector,\n           CASE WHEN device_name LIKE 'vending%' THEN event_value END AS vending\n    FROM mgbench.logs3\n    WHERE device_type = 'meter'\n  ) AS r\n  GROUP BY dt,\n           yr,\n           mo,\n           hr\n) AS s\nGROUP BY yr,\n         mo\nORDER BY yr,\n         mo;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "UV8M4MAGS2PWAUOAYAAARM",
		"name": "Cell towers by MCC",
		"group": "geo",
		"comment": "",
		"query": "SELECT mcc, count() FROM geo.cell_towers GROUP BY mcc ORDER BY count() DESC LIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "VYCIREOC1QSOPKUVANIUZK",
		"name": "Cell towers by type",
		"group": "geo",
		"comment": "",
		"query": "SELECT radio, count() AS c FROM geo.cell_towers GROUP BY radio ORDER BY c DESC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "2F9AQGB8CJR2DZ7ZAPY73Y",
		"name": "Number of cell towers in Moscow",
		"group": "geo",
		"comment": "",
		"query": "SELECT count() FROM geo.cell_towers\nWHERE pointInPolygon((lon, lat), (SELECT * FROM geo.moscow))",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "CMRQXM78SRPEZ9XU65GTQM",
		"name": "Number of rows",
		"group": "covid",
		"comment": "",
		"query": "SELECT formatReadableQuantity(count())\nFROM covid.covid19;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "356YYFGKQ2ED9OKIPNSRMC",
		"name": "Number of cases confirmed",
		"group": "covid",
		"comment": "",
		"query": "SELECT formatReadableQuantity(sum(new_confirmed))\nFROM covid.covid19;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "OBVBSACGRIAMJI16AI42VM",
		"name": "Daily averages of new case",
		"group": "covid",
		"comment": "",
		"query": "SELECT\n   AVG(new_confirmed) OVER (PARTITION BY location_key ORDER BY date ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING) AS cases_smoothed,\n   new_confirmed,\n   location_key,\n   date\nFROM covid.covid19;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "8KWGRUKIYUTKWVQW4CBYDP",
		"name": "Lag new cases each day for US-DC",
		"group": "covid",
		"comment": "",
		"query": "WITH latest_deaths_data AS\n   ( SELECT location_key,\n            date,\n            new_deceased,\n            new_confirmed,\n            ROW_NUMBER() OVER (PARTITION BY location_key ORDER BY date DESC) as rn\n     FROM covid.covid19)\nSELECT location_key,\n       date,\n       new_deceased,\n       new_confirmed,\n       rn\nFROM latest_deaths_data\nWHERE rn=1;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "2MENTDSVJQML2VRCO2UTII",
		"name": "Percentage new cases change per day",
		"group": "covid",
		"comment": "",
		"query": "WITH confirmed_lag AS (\n  SELECT\n    *,\n    lagInFrame(new_confirmed) OVER(\n      PARTITION BY location_key\n      ORDER BY date\n    ) AS confirmed_previous_day\n  FROM covid.covid19\n),\nconfirmed_percent_change AS (\n  SELECT\n    *,\n    COALESCE(ROUND((new_confirmed - confirmed_previous_day) / confirmed_previous_day * 100), 0) AS percent_change\n  FROM confirmed_lag\n)\nSELECT\n  date,\n  new_confirmed,\n  percent_change,\n  CASE\n    WHEN percent_change > 0 THEN 'increase'\n    WHEN percent_change = 0 THEN 'no change'\n    ELSE 'decrease'\n  END AS trend\nFROM confirmed_percent_change\nWHERE location_key = 'US_DC';",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "HQXNQZE26Z1QWYP9KC76ML",
		"name": "Most common ingredients",
		"group": "food",
		"comment": "",
		"query": "SELECT\n    arrayJoin(NER) AS k,\n    count() AS c\nFROM food.recipes\nGROUP BY k\nORDER BY c DESC\nLIMIT 50",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "1MXMHASDLEQIP4P1D1STND",
		"name": "Usage per machine",
		"group": "mgbench",
		"comment": "",
		"query": "SELECT machine_name,\n       MIN(cpu) AS cpu_min,\n       MAX(cpu) AS cpu_max,\n       AVG(cpu) AS cpu_avg,\n       MIN(net_in) AS net_in_min,\n       MAX(net_in) AS net_in_max,\n       AVG(net_in) AS net_in_avg,\n       MIN(net_out) AS net_out_min,\n       MAX(net_out) AS net_out_max,\n       AVG(net_out) AS net_out_avg\nFROM (\n  SELECT machine_name,\n         COALESCE(cpu_user, 0.0) AS cpu,\n         COALESCE(bytes_in, 0.0) AS net_in,\n         COALESCE(bytes_out, 0.0) AS net_out\n  FROM mgbench.logs1\n  WHERE machine_name IN ('anansi','aragog','urd')\n    AND log_time >= TIMESTAMP '2017-01-11 00:00:00'\n) AS r\nGROUP BY machine_name",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "478GCPU7LRTSZJBNY3EJT3",
		"name": "License types per dependencies",
		"group": "default",
		"comment": "",
		"query": "SELECT library_name, license_type, license_path FROM system.licenses ORDER BY library_name COLLATE 'en'",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "7YB4Q9HMD22ZV7VQWBFREA",
		"name": "Number cumulative contributors",
		"group": "git",
		"comment": "",
		"query": "WITH states AS\n    (\n        SELECT\n            month,\n            uniqState(actor_login) AS uniq_users\n        FROM git.github_events\n        WHERE (repo_name LIKE 'ClickHouse%') AND (event_type = 'PullRequestEvent')\n        GROUP BY toStartOfMonth(created_at) AS month\n        ORDER BY month ASC\n    )\nSELECT\n    month,\n    uniqMerge(uniq_users) OVER (ORDER BY month ASC) AS cul_users\nFROM states",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "KIZPJXDYG1QB6DQDFSAVIE",
		"name": "Number of unique and cumulative contributors",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    month,\n    arrayUniq(cul_users) AS cul_users,\n    arrayUniq(uniq_users) AS uniq_users\nFROM\n(\n    SELECT\n        month,\n        groupArrayDistinctArray(uniq_users) OVER (ORDER BY month ASC) AS cul_users,\n        groupArrayDistinct(actor_login) AS uniq_users\n    FROM git.github_events\n    WHERE (repo_name LIKE 'ClickHouse%') AND (event_type = 'PullRequestEvent')\n    GROUP BY toStartOfMonth(created_at) AS month\n    ORDER BY month ASC\n)\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "DCQPNPAIMAQXRLHYURLKVJ",
		"name": "Show tables",
		"group": "git",
		"comment": "",
		"query": "SHOW TABLES IN git",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9YHSK62D6WHC5ARCBOJEO7",
		"name": "Show events from dbt-clickhouse repo",
		"group": "git",
		"comment": "",
		"query": "SELECT * FROM git.github_events WHERE repo_name LIKE '%/dbt-clickhouse' ORDER BY created_at ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "1IXC5PU4QCXSH5DHGQRU6F",
		"name": "Show events from Clickhouse/dbt-clickhouse repo",
		"group": "git",
		"comment": "",
		"query": "SELECT * FROM git.github_events WHERE repo_name LIKE 'ClickHouse/dbt-clickhouse' ORDER BY created_at ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JAUTYJJXBOSATPJD9B624X",
		"name": "Select 1 event",
		"group": "git",
		"comment": "",
		"query": "SELECT * FROM git.github_events LIMIT 1",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "1BSPOBWAT6PUOCYXYNPNML",
		"name": "Compute if commit days are consecutive",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    author,\n    toDate(day) as day,\n    any(day) OVER (PARTITION BY author ORDER BY day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_commit,\n    dateDiff('day', previous_commit, day) AS day_diff,\n    if(day_diff = 1, 1, 0) AS consecutive\nFROM\n(\n   SELECT author, toStartOfDay(time) AS day FROM git.clickhouse_commits GROUP BY author, day ORDER BY author ASC, day ASC\n)\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "WSHUEPJP9TNJUH7QITWWOR",
		"name": "Average and median rewrite time across all files",
		"group": "git",
		"comment": "",
		"query": "WITH\n    changes AS\n    (\n        SELECT\n            path,\n            commit_hash,\n            max_time,\n            type,\n            num_added,\n            num_deleted,\n            sum(num_added - num_deleted) OVER (PARTITION BY path ORDER BY max_time ASC) AS current_size,\n            if(current_size > 0, num_added / current_size, 0) AS percent_add,\n            if(current_size > 0, num_deleted / current_size, 0) AS percent_delete\n        FROM\n        (\n            SELECT\n                path,\n                max(time) AS max_time,\n                commit_hash,\n                any(lines_added) AS num_added,\n                any(lines_deleted) AS num_deleted,\n                any(change_type) AS type\n            FROM git.clickhouse_file_changes\n            WHERE (change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql'))\n            GROUP BY\n                path,\n                commit_hash\n            ORDER BY\n                path ASC,\n                max_time ASC\n        )\n    ),\n    rewrites AS\n    (\n        SELECT\n            *,\n            any(max_time) OVER (PARTITION BY path ORDER BY max_time ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_rewrite,\n            dateDiff('day', previous_rewrite, max_time) AS rewrite_days\n        FROM changes\n        WHERE (type = 'Modify') AND (percent_add >= 0.5) AND (percent_delete >= 0.5) AND (current_size > 50)\n    )\nSELECT\n    avgIf(rewrite_days, rewrite_days > 0) AS avg_rewrite_time,\n    quantilesTimingIf(0.5)(rewrite_days, rewrite_days > 0) AS half_life\nFROM rewrites",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "COAZRFX2YFULDBXRQTCQ1S",
		"name": "All commit messages for specific topic",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    time,\n    substring(commit_hash, 1, 11) AS commit,\n    change_type,\n    author,\n    path,\n    old_path,\n    lines_added,\n    lines_deleted,\n    commit_message\nFROM git.clickhouse_file_changes\nWHERE path = 'src/Storages/StorageReplicatedMergeTree.cpp'\nORDER BY time DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "5AUH3VVENJ6CFEFWDKW5ZH",
		"name": "Author with commits for the most number of consecutive days",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    author,\n    toStartOfDay(time) AS day\nFROM git.clickhouse_commits\nGROUP BY\n    author,\n    day\nORDER BY\n    author ASC,\n    day ASC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "7ARCDLHQCESYBP3INDPTVO",
		"name": "Get one hash and time",
		"group": "git",
		"comment": "",
		"query": "SELECT hash, time FROM git.clickhouse_commits ORDER BY time DESC LIMIT 1",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "AKS9SYLARFMZCHGAAQNEBN",
		"name": "Review all line changes for specific topic",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    time,\n    substring(commit_hash, 1, 11) AS commit,\n    sign,\n    line_number_old,\n    line_number_new,\n    author,\n    line\nFROM git.clickhouse_line_changes\nWHERE path = 'src/Storages/StorageReplicatedMergeTree.cpp'\nORDER BY line_number_new ASC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "2HNFWPCFWEEY92WTAPMA7W",
		"name": "Find current active files",
		"group": "git",
		"comment": "",
		"query": "SELECT path\nFROM\n(\n    SELECT\n        old_path AS path,\n        max(time) AS last_time,\n        2 AS change_type\n    FROM git.clickhouse_file_changes\n    GROUP BY old_path\n    UNION ALL\n    SELECT\n        path,\n        max(time) AS last_time,\n        argMax(change_type, time) AS change_type\n    FROM git.clickhouse_file_changes\n    GROUP BY path\n)\nGROUP BY path\nHAVING (argMax(change_type, last_time) != 2) AND NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)') ORDER BY path\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "1OXCKMOH2JVMSHD3NS2WW6",
		"name": "Find number of active files",
		"group": "git",
		"comment": "",
		"query": "SELECT uniq(path)\nFROM\n(\n    SELECT path\n    FROM\n    (\n        SELECT\n            old_path AS path,\n            max(time) AS last_time,\n            2 AS change_type\n        FROM git.clickhouse_file_changes\n        GROUP BY old_path\n        UNION ALL\n        SELECT\n            path,\n            max(time) AS last_time,\n            argMax(change_type, time) AS change_type\n        FROM git.clickhouse_file_changes\n        GROUP BY path\n    )\n    GROUP BY path\n    HAVING (argMax(change_type, last_time) != 2) AND NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)') ORDER BY path\n)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "SCXWMR9GBMJ9UNZYQXQBFA",
		"name": "List of changes for renamed file",
		"group": "git",
		"comment": "",
		"query": "SELECT\n      change_type,\n      path,\n      old_path,\n      time,\n      commit_hash\n  FROM git.clickhouse_file_changes\n  WHERE (path = 'src/Functions/geometryFromColumn.h') OR (old_path = 'src/Functions/geometryFromColumn.h')\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "MHXPSBNPTDMJYR3OYSXVR7",
		"name": "List files with most modifications",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    path,\n    sum(lines_added) + sum(lines_deleted) AS modifications\nFROM git.clickhouse_file_changes\nWHERE (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql'))\nGROUP BY path\nORDER BY modifications DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GED2STFSYJDRAA59H8RLIV",
		"name": "Number of commits per week day",
		"group": "geo",
		"comment": "",
		"query": "SELECT\n    day_of_week,\n    count() AS c\nFROM git.clickhouse_commits\nGROUP BY dayOfWeek(time) AS day_of_week",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "REZRXDVU7CAWT5WKNJSTNY",
		"name": "History of subdirectory/file",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    week,\n    sum(lines_added) AS lines_added,\n    sum(lines_deleted) AS lines_deleted,\n    uniq(commit_hash) AS num_commits,\n    uniq(author) AS authors\nFROM git.clickhouse_file_changes\nWHERE path LIKE 'src/Storages%'\nGROUP BY toStartOfWeek(time) AS week\nORDER BY week ASC\nLIMIT 10\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "CYQFNQNK9TAMPU2OZ8KG5Y",
		"name": "List files with maximum number of authors",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    path,\n    uniq(author) AS num_authors\nFROM git.clickhouse_file_changes\nWHERE path IN (current_files)\nGROUP BY path\nORDER BY num_authors DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "VWPBPGRZVGTHOCQYWNQZNT",
		"name": "Oldest lines of code in the repository",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    any(path) AS file_path,\n    line,\n    max(time) AS latest_change,\n    any(file_change_type)\nFROM git.clickhouse_line_changes\nWHERE path IN (current_files)\nGROUP BY line\nORDER BY latest_change ASC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "EONJVEYDCODCUZUF8SNB4Y",
		"name": "Files with longest history",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    count() AS c,\n    path,\n    max(time) AS latest_change\nFROM git.clickhouse_file_changes\nWHERE path IN (current_files)\nGROUP BY path\nORDER BY c DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BA4RZUXUHNQBH9YK7F2T9J",
		"name": "Distribution of contribution per day of the month",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    day,\n    bar(docs_ratio * 1000, 0, 100, 100) AS bar\nFROM\n(\n    SELECT\n        day,\n        countIf(file_extension IN ('h', 'cpp', 'sql')) AS code,\n        countIf(file_extension = 'md') AS docs,\n        docs / (code + docs) AS docs_ratio\n    FROM git.clickhouse_line_changes\n    WHERE (sign = 1) AND (file_extension IN ('h', 'cpp', 'sql', 'md'))\n    GROUP BY dayOfMonth(time) AS day\n)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "MT8WBABUKYBYSBA78W5TML",
		"name": "Authors with the most diverse impact",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    author,\n    uniq(path) AS num_files\nFROM git.clickhouse_file_changes\nWHERE (change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql'))\nGROUP BY author\nORDER BY num_files DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "4Q3D67FWRIVWTY8EIDDE5U",
		"name": "Authors with most recent diverse contribution",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    author,\n    sum(num_files_commit) AS num_files\nFROM\n(\n    SELECT\n        author,\n        commit_hash,\n        uniq(path) AS num_files_commit,\n        max(time) AS commit_time\n    FROM git.clickhouse_file_changes\n    WHERE (change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql'))\n    GROUP BY\n        author,\n        commit_hash\n    ORDER BY\n        author ASC,\n        commit_time DESC\n    LIMIT 3 BY author\n)\nGROUP BY author\nORDER BY num_files DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "OKGZBACRHVGCRAGCZAJKMF",
		"name": "Favorite files for an author",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    path,\n    count() AS c\nFROM git.clickhouse_file_changes\nWHERE (author = 'Alexey Milovidov') AND (path IN (current_files))\nGROUP BY path\nORDER BY c DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "P9PBDZGOSVTKXEXU73ZNAJ",
		"name": "Favorite code files for an author",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    base,\n    count() AS c\nFROM git.clickhouse_file_changes\nWHERE (author = 'Alexey Milovidov') AND (file_extension IN ('h', 'cpp', 'sql'))\nGROUP BY basename(path) AS base\nORDER BY c DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "PVSDOHZYUMRDDUZFEYJC7J",
		"name": "Largest files",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    path,\n    sum(lines_added) - sum(lines_deleted) AS num_lines,\n    uniqExact(author) AS num_authors,\n    num_lines / num_authors AS lines_author_ratio\nFROM git.clickhouse_file_changes\nWHERE path IN (current_files)\nGROUP BY path\nORDER BY lines_author_ratio DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BZHGWUIZMPZZUHS5XRBK2M",
		"name": "Largest code files",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    path,\n    sum(lines_added) - sum(lines_deleted) AS num_lines,\n    uniqExact(author) AS num_authors,\n    num_lines / num_authors AS lines_author_ratio\nFROM git.clickhouse_file_changes\nWHERE (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql'))\nGROUP BY path\nORDER BY lines_author_ratio DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "RMHHZEDHFUCBGRQVQA2732",
		"name": "Largest recent code files with ",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    min(time) AS min_date,\n    path,\n    sum(lines_added) - sum(lines_deleted) AS num_lines,\n    uniqExact(author) AS num_authors,\n    num_lines / num_authors AS lines_author_ratio\nFROM git.clickhouse_file_changes\nWHERE (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql'))\nGROUP BY path\nHAVING min_date <= (now() - toIntervalYear(1))\nORDER BY lines_author_ratio DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "PF3KEMYG5CVLJGCFYQEGB1",
		"name": "Commits distribution by weekday",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    dayOfWeek,\n    uniq(commit_hash) AS commits,\n    sum(lines_added) AS lines_added,\n    sum(lines_deleted) AS lines_deleted\nFROM git.clickhouse_file_changes\nWHERE path LIKE 'src/Functions%'\nGROUP BY toDayOfWeek(time) AS dayOfWeek",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "Q4VDVKEGHHRBCUJHNCVTF1",
		"name": "Commits distribution by hour of the day",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    hourOfDay,\n    uniq(commit_hash) AS commits,\n    sum(lines_added) AS lines_added,\n    sum(lines_deleted) AS lines_deleted\nFROM git.clickhouse_file_changes\nWHERE path LIKE 'src/Functions%'\nGROUP BY toHour(time) AS hourOfDay",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9AZ8CENV8N91YGW7T6IB68",
		"name": "Charts commits distribution by hour of the day",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    hourOfDay,\n    bar(commits, 0, 400, 50) AS commits,\n    bar(lines_added, 0, 30000, 50) AS lines_added,\n    bar(lines_deleted, 0, 15000, 50) AS lines_deleted\nFROM\n(\n    SELECT\n        hourOfDay,\n        uniq(commit_hash) AS commits,\n        sum(lines_added) AS lines_added,\n        sum(lines_deleted) AS lines_deleted\n    FROM git.clickhouse_file_changes\n    WHERE path LIKE 'src/Functions%'\n    GROUP BY toHour(time) AS hourOfDay\n)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "448O8GWAHY3EM6ZZ7AGLAM",
		"name": "Authors that tends to rewrite other authors code",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    prev_author || '(a)' as add_author,\n    author  || '(d)' as delete_author,\n    count() AS c\nFROM git.clickhouse_line_changes\nWHERE (sign = -1) AND (file_extension IN ('h', 'cpp')) AND (line_type NOT IN ('Punct', 'Empty')) AND (author != prev_author) AND (prev_author != '')\nGROUP BY\n    prev_author,\n    author\nORDER BY c DESC\nLIMIT 1 BY prev_author\nLIMIT 100",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "WXPKFJCAHOKYKEVTWNFVCY",
		"name": "Top contributors per week day",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    day_of_week,\n    author,\n    count() AS c\nFROM git.clickhouse_commits\nGROUP BY\n    dayOfWeek(time) AS day_of_week,\n    author\nORDER BY\n    day_of_week ASC,\n    c DESC\nLIMIT 1 BY day_of_week",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "8YRJGHFTNJAWJ96XCJKKEH",
		"name": "Top contributors per week day for last year",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    day_of_week,\n    author,\n    count() AS c\nFROM git.clickhouse_commits\nWHERE time > (now() - toIntervalYear(1))\nGROUP BY\n    dayOfWeek(time) AS day_of_week,\n    author\nORDER BY\n    day_of_week ASC,\n    c DESC\nLIMIT 1 BY day_of_week",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "VQF4KMRDSUEXGS1JFVDJHV",
		"name": "Top contributor each day as a fraction of the total work performed in the last year",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    top_author.day_of_week,\n    top_author.author,\n    top_author.author_work / all_work.total_work AS top_author_percent\nFROM\n(\n    SELECT\n        day_of_week,\n        author,\n        sum(lines_added) + sum(lines_deleted) AS author_work\n    FROM git.clickhouse_file_changes\n    WHERE time > (now() - toIntervalYear(1))\n    GROUP BY\n        author,\n        dayOfWeek(time) AS day_of_week\n    ORDER BY\n        day_of_week ASC,\n        author_work DESC\n    LIMIT 1 BY day_of_week\n) AS top_author\nINNER JOIN\n(\n    SELECT\n        day_of_week,\n        sum(lines_added) + sum(lines_deleted) AS total_work\n    FROM git.clickhouse_file_changes\n    WHERE time > (now() - toIntervalYear(1))\n    GROUP BY dayOfWeek(time) AS day_of_week\n) AS all_work USING (day_of_week)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "6YWAUQYPZINZDJGBEZBNWG",
		"name": "Distribution of code age across repository",
		"group": "git",
		"comment": "",
		"query": "WITH current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    )\nSELECT\n    concat(root, '/', sub_folder) AS folder,\n    round(avg(days_present)) AS avg_age_of_files,\n    min(days_present) AS min_age_files,\n    max(days_present) AS max_age_files,\n    count() AS c\nFROM\n(\n    SELECT\n        path,\n        dateDiff('day', min(time), toDate('2022-11-03')) AS days_present\n    FROM git.clickhouse_file_changes\n    WHERE (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql'))\n    GROUP BY path\n)\nGROUP BY\n    splitByChar('/', path)[1] AS root,\n    splitByChar('/', path)[2] AS sub_folder\nORDER BY\n    root ASC,\n    c DESC\nLIMIT 5 BY root\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "T4DTWTB36WFSEYAZLMGRNF",
		"name": "Number of an authors contribution divided by the number of lines they have had removed by another contributor",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    k,\n    written_code.c,\n    removed_code.c,\n    removed_code.c / written_code.c AS remove_ratio\nFROM\n(\n    SELECT\n        author AS k,\n        count() AS c\n    FROM git.clickhouse_line_changes\n    WHERE (sign = 1) AND (file_extension IN ('h', 'cpp')) AND (line_type NOT IN ('Punct', 'Empty'))\n    GROUP BY k\n) AS written_code\nINNER JOIN\n(\n    SELECT\n        prev_author AS k,\n        count() AS c\n    FROM git.clickhouse_line_changes\n    WHERE (sign = -1) AND (file_extension IN ('h', 'cpp')) AND (line_type NOT IN ('Punct', 'Empty')) AND (author != prev_author)\n    GROUP BY k\n) AS removed_code USING (k)\nWHERE written_code.c > 1000\nORDER BY remove_ratio DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "5PL1QLNSH6QQTR8H9HINNP",
		"name": "Files with most rewrites",
		"group": "git",
		"comment": "",
		"query": "WITH\n    current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    ),\n    changes AS\n    (\n        SELECT\n            path,\n            max(time) AS max_time,\n            commit_hash,\n            any(lines_added) AS num_added,\n            any(lines_deleted) AS num_deleted,\n            any(change_type) AS type\n        FROM git.clickhouse_file_changes\n        WHERE (change_type IN ('Add', 'Modify')) AND (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql'))\n        GROUP BY\n            path,\n            commit_hash\n        ORDER BY\n            path ASC,\n            max_time ASC\n    ),\n    rewrites AS\n    (\n        SELECT\n            path,\n            commit_hash,\n            max_time,\n            type,\n            num_added,\n            num_deleted,\n            sum(num_added - num_deleted) OVER (PARTITION BY path ORDER BY max_time ASC) AS current_size,\n            if(current_size > 0, num_added / current_size, 0) AS percent_add,\n            if(current_size > 0, num_deleted / current_size, 0) AS percent_delete\n        FROM changes\n    )\nSELECT\n    path,\n    count() AS num_rewrites\nFROM rewrites\nWHERE (type = 'Modify') AND (percent_add >= 0.5) AND (percent_delete >= 0.5) AND (current_size > 50)\nGROUP BY path\nORDER BY num_rewrites DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GVF23LEZTNZI22BT8LZBBE",
		"name": "Find weekday when the code have the highest chance to stay",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    day_of_week_added,\n    count() AS num,\n    avg(days_present) AS avg_days_present\nFROM\n(\n    SELECT\n        added_code.line,\n        added_code.time AS added_day,\n        dateDiff('day', added_code.time, removed_code.time) AS days_present\n    FROM\n    (\n        SELECT\n            path,\n            line,\n            max(time) AS time\n        FROM git.clickhouse_line_changes\n        WHERE (sign = 1) AND (line_type NOT IN ('Punct', 'Empty'))\n        GROUP BY\n            path,\n            line\n    ) AS added_code\n    INNER JOIN\n    (\n        SELECT\n            path,\n            line,\n            max(time) AS time\n        FROM git.clickhouse_line_changes\n        WHERE (sign = -1) AND (line_type NOT IN ('Punct', 'Empty'))\n        GROUP BY\n            path,\n            line\n    ) AS removed_code USING (path, line)\n    WHERE removed_code.time > added_code.time\n)\nGROUP BY dayOfWeek(added_day) AS day_of_week_added",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "3CYYT7HEHWRFHVCM9JCKSU",
		"name": "Files sorted by average code age",
		"group": "git",
		"comment": "",
		"query": "WITH\n    current_files AS\n    (\n        SELECT path\n        FROM\n        (\n            SELECT\n                old_path AS path,\n                max(time) AS last_time,\n                2 AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY old_path\n            UNION ALL\n            SELECT\n                path,\n                max(time) AS last_time,\n                argMax(change_type, time) AS change_type\n            FROM git.clickhouse_file_changes\n            GROUP BY path\n        )\n        GROUP BY path\n        HAVING (argMax(change_type, last_time) != 2) AND (NOT match(path, '(^dbms/)|(^libs/)|(^tests/testflows/)|(^programs/server/store/)'))\n        ORDER BY path ASC\n    ),\n    lines_removed AS\n    (\n        SELECT\n            added_code.path AS path,\n            added_code.line,\n            added_code.time AS added_day,\n            dateDiff('day', added_code.time, removed_code.time) AS days_present\n        FROM\n        (\n            SELECT\n                path,\n                line,\n                max(time) AS time,\n                any(file_extension) AS file_extension\n            FROM git.clickhouse_line_changes\n            WHERE (sign = 1) AND (line_type NOT IN ('Punct', 'Empty'))\n            GROUP BY\n                path,\n                line\n        ) AS added_code\n        INNER JOIN\n        (\n            SELECT\n                path,\n                line,\n                max(time) AS time\n            FROM git.clickhouse_line_changes\n            WHERE (sign = -1) AND (line_type NOT IN ('Punct', 'Empty'))\n            GROUP BY\n                path,\n                line\n        ) AS removed_code USING (path, line)\n        WHERE (removed_code.time > added_code.time) AND (path IN (current_files)) AND (file_extension IN ('h', 'cpp', 'sql'))\n    )\nSELECT\n    path,\n    avg(days_present) AS avg_code_age\nFROM lines_removed\nGROUP BY path\nORDER BY avg_code_age DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JGKZSEQDPDTDKZXD3ZCGLE",
		"name": "Authors who write more tests",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    author,\n    countIf((file_extension IN ('h', 'cpp', 'sql', 'sh', 'py', 'expect')) AND (path LIKE '%tests%')) AS test,\n    countIf((file_extension IN ('h', 'cpp', 'sql')) AND (NOT (path LIKE '%tests%'))) AS code,\n    code / (code + test) AS ratio_code\nFROM git.clickhouse_file_changes\nGROUP BY author\nHAVING code > 20\nORDER BY code DESC\nLIMIT 20",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "S5AJIIRGSUAY1JXEVHQDAK",
		"name": "Plot distribution of authors who write more tests",
		"group": "geo",
		"comment": "",
		"query": "WITH (\n        SELECT histogram(10)(ratio_code) AS hist\n        FROM\n        (\n            SELECT\n                author,\n                countIf((file_extension IN ('h', 'cpp', 'sql', 'sh', 'py', 'expect')) AND (path LIKE '%tests%')) AS test,\n                countIf((file_extension IN ('h', 'cpp', 'sql')) AND (NOT (path LIKE '%tests%'))) AS code,\n                code / (code + test) AS ratio_code\n            FROM git.clickhouse_file_changes\n            GROUP BY author\n            HAVING code > 20\n            ORDER BY code DESC\n            LIMIT 20\n        )\n    ) AS hist\nSELECT\n    arrayJoin(hist).1 AS lower,\n    arrayJoin(hist).2 AS upper,\n    bar(arrayJoin(hist).3, 0, 100, 500) AS bar",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "EXPHDIURBTOXXOK1TGNNYD",
		"name": "Authors with most comments ratio",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    author,\n    avg(ratio_comments) AS avg_ratio_comments,\n    sum(code) AS code\nFROM\n(\n    SELECT\n        author,\n        commit_hash,\n        countIf(line_type = 'Comment') AS comments,\n        countIf(line_type = 'Code') AS code,\n        if(comments > 0, comments / (comments + code), 0) AS ratio_comments\n    FROM git.clickhouse_line_changes\n    GROUP BY\n        author,\n        commit_hash\n)\nGROUP BY author\nORDER BY code DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "SBHEWR8XC4PRHY13HPPKCN",
		"name": "Average time before code will be rewritten ",
		"group": "git",
		"comment": "",
		"query": "WITH author_ratios_by_offset AS\n    (\n        SELECT\n            author,\n            dateDiff('week', start_dates.start_date, contributions.week) AS week_offset,\n            ratio_code\n        FROM\n        (\n            SELECT\n                author,\n                toStartOfWeek(min(time)) AS start_date\n            FROM git.clickhouse_line_changes\n            WHERE file_extension IN ('h', 'cpp', 'sql')\n            GROUP BY author AS start_dates\n        ) AS start_dates\n        INNER JOIN\n        (\n            SELECT\n                author,\n                countIf(line_type = 'Code') AS code,\n                countIf((line_type = 'Comment') OR (line_type = 'Punct')) AS comments,\n                comments / (comments + code) AS ratio_code,\n                toStartOfWeek(time) AS week\n            FROM git.clickhouse_line_changes\n            WHERE (file_extension IN ('h', 'cpp', 'sql')) AND (sign = 1)\n            GROUP BY\n                time,\n                author\n            HAVING code > 20\n            ORDER BY\n                author ASC,\n                time ASC\n        ) AS contributions USING (author)\n    )\nSELECT\n    week_offset,\n    avg(ratio_code) AS avg_code_ratio\nFROM author_ratios_by_offset\nGROUP BY week_offset\nHAVING (week_offset % 10) = 0\nORDER BY week_offset ASC\nLIMIT 20\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "8PQNWEWHAJTGN6FTX59KH2",
		"name": "Day of the month with most number of rewrites",
		"group": "git",
		"comment": "",
		"query": "WITH\n    changes AS\n    (\n        SELECT\n            path,\n            commit_hash,\n            max_time,\n            type,\n            num_added,\n            num_deleted,\n            sum(num_added - num_deleted) OVER (PARTITION BY path ORDER BY max_time ASC) AS current_size,\n            if(current_size > 0, num_added / current_size, 0) AS percent_add,\n            if(current_size > 0, num_deleted / current_size, 0) AS percent_delete\n        FROM\n        (\n            SELECT\n                path,\n                max(time) AS max_time,\n                commit_hash,\n                any(file_lines_added) AS num_added,\n                any(file_lines_deleted) AS num_deleted,\n                any(file_change_type) AS type\n            FROM git.clickhouse_line_changes\n            WHERE (file_change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql'))\n            GROUP BY\n                path,\n                commit_hash\n            ORDER BY\n                path ASC,\n                max_time ASC\n        )\n    ),\n    rewrites AS\n    (\n        SELECT any(max_time) OVER (PARTITION BY path ORDER BY max_time ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_rewrite\n        FROM changes\n        WHERE (type = 'Modify') AND (percent_add >= 0.5) AND (percent_delete >= 0.5) AND (current_size > 50)\n    )\nSELECT\n    dayOfWeek(previous_rewrite) AS dayOfWeek,\n    count() AS num_re_writes\nFROM rewrites\nGROUP BY dayOfWeek",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BKHLVVWN5SET1VTIFQ8JVK",
		"name": "Authors with the most sticky code",
		"group": "git",
		"comment": "",
		"query": "WITH\n    changes AS\n    (\n        SELECT\n            path,\n            author,\n            commit_hash,\n            max_time,\n            type,\n            num_added,\n            num_deleted,\n            sum(num_added - num_deleted) OVER (PARTITION BY path ORDER BY max_time ASC) AS current_size,\n            if(current_size > 0, num_added / current_size, 0) AS percent_add,\n            if(current_size > 0, num_deleted / current_size, 0) AS percent_delete\n        FROM\n        (\n            SELECT\n                path,\n                any(author) AS author,\n                max(time) AS max_time,\n                commit_hash,\n                any(file_lines_added) AS num_added,\n                any(file_lines_deleted) AS num_deleted,\n                any(file_change_type) AS type\n            FROM git.clickhouse_line_changes\n            WHERE (file_change_type IN ('Add', 'Modify')) AND (file_extension IN ('h', 'cpp', 'sql'))\n            GROUP BY\n                path,\n                commit_hash\n            ORDER BY\n                path ASC,\n                max_time ASC\n        )\n    ),\n    rewrites AS\n    (\n        SELECT\n            *,\n            any(max_time) OVER (PARTITION BY path ORDER BY max_time ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_rewrite,\n            dateDiff('day', previous_rewrite, max_time) AS rewrite_days,\n            any(author) OVER (PARTITION BY path ORDER BY max_time ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS prev_author\n        FROM changes\n        WHERE (type = 'Modify') AND (percent_add >= 0.5) AND (percent_delete >= 0.5) AND (current_size > 50)\n    )\nSELECT\n    prev_author,\n    avg(rewrite_days) AS c,\n    uniq(path) AS num_files\nFROM rewrites\nGROUP BY prev_author\nHAVING num_files > 2\nORDER BY c DESC\nLIMIT 10\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "S3E64UYCAMDAYJRSXINVFR",
		"name": "Most consecutive days of commits by an author",
		"group": "git",
		"comment": "",
		"query": "WITH commit_days AS\n    (\n        SELECT\n            author,\n            day,\n            any(day) OVER (PARTITION BY author ORDER BY day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS previous_commit,\n            dateDiff('day', previous_commit, day) AS days_since_last,\n            if(days_since_last = 1, 1, 0) AS consecutive_day\n        FROM\n        (\n            SELECT\n                author,\n                toStartOfDay(time) AS day\n            FROM git.clickhouse_commits\n            GROUP BY\n                author,\n                day\n            ORDER BY\n                author ASC,\n                day ASC\n        )\n    )\nSELECT\n    author,\n    arrayMax(arrayMap(x -> length(x), arraySplit(x -> (x = 0), groupArray(consecutive_day)))) AS max_consecutive_days\nFROM commit_days\nGROUP BY author\nORDER BY max_consecutive_days DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "AKTW3Z8JZAPQ4H9BH2ZFRX",
		"name": "Line by line commit history of a file",
		"group": "git",
		"comment": "",
		"query": "SELECT\n    time,\n    path,\n    old_path,\n    commit_hash,\n    commit_message\nFROM git.clickhouse_file_changes\nWHERE (path = 'src/Storages/StorageReplicatedMergeTree.cpp') AND (change_type = 'Rename')",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "KB5KQJJFNBKHE5GBUJCP1B",
		"name": "Menu with caviar",
		"group": "food",
		"comment": "",
		"query": "SELECT\n    round(toUInt32OrZero(extract(menu_date, '^\\\\d{4}')), -1) AS d,\n    count(),\n    round(avg(price), 2),\n    bar(avg(price), 0, 50, 100),\n    any(dish_name)\nFROM food.menu_item_denorm\nWHERE (menu_currency IN ('Dollars', '')) AND (d > 0) AND (d < 2022) AND (dish_name ILIKE '%caviar%')\nGROUP BY d\nORDER BY d ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "KBGB8WAATJ1TEZSHUTF197",
		"name": "Select ten rows",
		"group": "uk",
		"comment": "",
		"query": "SELECT * FROM uk.uk_price_paid LIMIT 10    \n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "TRCWH5ZETY4SEEK8ISCCAX",
		"name": "Most expensive district",
		"group": "uk",
		"comment": "",
		"query": "SELECT town, district, count() AS c, round(avg(price)) AS price, bar(price, 0, 5000000, 100) FROM uk.uk_price_paid WHERE date >= '2020-01-01' GROUP BY town, district HAVING c >= 100 ORDER BY price DESC LIMIT 100",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "EAI3T1FVZSGSRJFSSDCCQP",
		"name": "Average price per town",
		"group": "uk",
		"comment": "",
		"query": "SELECT \n    town,\n    avg(price) AS avg_price \nFROM uk.uk_price_paid\nGROUP BY town;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "3CQY9DMYYK7PJSDRPGBJAE",
		"name": "Average price per year",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n    toYear(date) AS year,\n    round(avg(price)) AS price\nFROM uk.uk_price_paid\nWHERE type = 'flat'\nGROUP BY year\nORDER BY year ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "VX9XNLHPDAU9BROIOJNFXH",
		"name": "Average price per district of Bristol",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n        postcode1,\n        round(avg(price)) AS price\nFROM uk.uk_price_paid\nWHERE (town = 'BRISTOL') AND (postcode1 != '')\nGROUP BY postcode1\nORDER BY price DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "EDRZIQMQN3FPZJEU3TPMKR",
		"name": "Median price change in London",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n        postcode1,\n        medianIf(price, toYear(date) = 2002) AS median_2002,\n        medianIf(price, toYear(date) = 2022) AS median_2022,\n        round(((median_2022 - median_2002) / median_2002) * 100) AS percent_change\nFROM uk.uk_price_paid\nWHERE town = 'LONDON'\nGROUP BY postcode1\nORDER BY percent_change DESC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "7PEVSKK5MBGK5PTEQ6FUOD",
		"name": "10 years price change per district",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n        postcode1,\n        medianIf(price, toYear(date) = 2002) AS median_2002,\n        medianIf(price, toYear(date) = 2021) AS median_2021,\n        round(((median_2021 - median_2002) / median_2002) * 100) AS percent_change\nFROM uk.uk_price_paid\nWHERE town = 'LONDON'\nGROUP BY postcode1\nORDER BY percent_change ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "6CZ8TRMMKWHYDE91A3KETE",
		"name": "Show create table",
		"group": "uk",
		"comment": "",
		"query": "SHOW CREATE TABLE uk.uk_price_paid",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "TEH4J3REPN2FNDRGCYDNM6",
		"name": "Top 3 largest sale in London",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n    county,\n    price\nFROM uk.uk_price_paid\nWHERE town = 'LONDON'\nORDER BY price DESC\nLIMIT 3",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "DXP1BNTN6YUGWXRZJET4AM",
		"name": "Top 3 largest sale in London - optimized primary keys",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n    county,\n    price\nFROM uk.uk_price_paid_oby_town_price\nWHERE town = 'LONDON'\nORDER BY price DESC\nLIMIT 3\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "5INADD1EKJOHLERC8VMGAP",
		"name": "Explain 1 - Top 3 largest sale in London - optimized primary keys",
		"group": "uk",
		"comment": "",
		"query": "EXPLAIN actions = 1\nSELECT\n    county,\n    price\nFROM uk.uk_price_paid_oby_town_price\nWHERE town = 'LONDON'\nORDER BY price DESC\nLIMIT 3",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "6EG4PWKERYSYU3BB6BMSDX",
		"name": "Explain Pipeline - Top 3 largest sale in London - optimized primary keys",
		"group": "uk",
		"comment": "",
		"query": "EXPLAIN PIPELINE\nSELECT\n    county,\n    price\nFROM uk.uk_price_paid\nWHERE town = 'LONDON'\nORDER BY price DESC\nLIMIT 3",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "AEZD2XA3HDMMAJDYTJCZLD",
		"name": "Top 3 most expensive counties",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n    county,\n    avg(price)\nFROM uk.uk_price_paid\nGROUP BY county\nORDER BY avg(price) DESC\nLIMIT 3\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "6IDMHK3OMR1C97J6M9EUQS",
		"name": "Select one row",
		"group": "uk",
		"comment": "",
		"query": "SELECT * FROM uk.uk_price_paid LIMIT 1",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "HDNRS1WAM3BEZKOEUWRAF3",
		"name": "Average price for one district",
		"group": "uk",
		"comment": "With optimize_aggregation_in_order=1, the query would be able to shortcut and as a result process less data.",
		"query": "SELECT\n    postcode1, postcode2,\n    formatReadableQuantity(avg(price)) AS avg_price\nFROM uk.uk_price_paid\nGROUP BY postcode1, postcode2\nLIMIT 1;",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "day",
			"yaxis": "change"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "5DVCXJZPH77BQJKREMEG8Z",
		"name": "Average house price and sales per month since 1995",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n    month,\n    countIf(duration = 'leasehold') AS `Leasehold Sold`,\n    countIf(duration = 'freehold') AS `Freehold Sold`,\n    avgIf(price, duration = 'freehold') AS `Average Freehold Price`,\n    avgIf(price, duration = 'leasehold') AS `Average Leasehold Price`\nFROM uk.uk_price_paid\nGROUP BY toStartOfMonth(date) AS month\nORDER BY month ASC",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "day",
			"yaxis": "change"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "W2VWYX9FLEK9MPXFEVM9UR",
		"name": "Regions with the largest percentage change in median house prices in the last 20 years",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n   code,\n   (anyIf(med_2020, med_2020 > 0) - anyIf(med_2000, med_2000 > 0)) / anyIf(med_2000, med_2000 > 0) AS percent_change\nFROM\n(\n   SELECT\n       code,\n       medianIf(price, year = 2000) AS med_2000,\n       medianIf(price, year = 2020) AS med_2020\n   FROM\n   (\n       SELECT\n           date,\n           price,\n           locality,\n           town,\n           district,\n           county,\n           code\n       FROM uk.uk_price_paid\n       LEFT JOIN uk.uk_codes AS codes ON (uk.uk_price_paid.county = codes.name) OR (uk.uk_price_paid.district = codes.name) OR (uk.uk_price_paid.town = codes.name) OR (uk.uk_price_paid.locality = codes.name) OR (replaceAll(uk.uk_price_paid.district, 'CITY OF ', '') = codes.name)\n   )\n   WHERE (code != '') AND ((toYear(date) = 2000) OR (toYear(date) = 2020))\n   GROUP BY\n       code,\n       toYear(date) AS year\n   ORDER BY code ASC\n)\nGROUP BY code\nORDER BY percent_change DESC",
		"chart": {
		  "type": "bar",
		  "config": {
			"xaxis": "year",
			"yaxis": "avg_precipitation",
			"series": "country",
			"stack": true
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "M4FSVBVMSHY98NKCQP8N4K",
		"name": "Ontime flight per day of the week",
		"group": "ontime",
		"comment": "",
		"query": "SELECT DayOfWeek, count(*) AS c\nFROM ontime.ontime\nWHERE Year>=2000 AND Year<=2008\nGROUP BY DayOfWeek\nORDER BY c DESC;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BIPDVQNIGVEZFQYFEFQB7O",
		"name": "Airport with most departures",
		"group": "opensky",
		"comment": "",
		"query": "SELECT\n    origin,\n    count(),\n    round(avg(geoDistance(longitude_1, latitude_1, longitude_2, latitude_2))) AS distance,\n    bar(distance, 0, 10000000, 100) AS bar\nFROM opensky.opensky\nWHERE origin != ''\nGROUP BY origin\nORDER BY count() DESC\nLIMIT 100",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9IUASIZZPK6JYG3BU4RPUM",
		"name": "Year start avg price per town",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n    toStartOfYear(date) AS time,\n    town,\n    round(avg(price)) AS price\nFROM uk.uk_price_paid\nWHERE town IN (\n    SELECT town\n    FROM uk.uk_price_paid\n    WHERE town != 'GATWICK'\n    GROUP BY town\n    ORDER BY avg(price) DESC\n    LIMIT 10\n)\nGROUP BY\n    time,\n    town\nORDER BY time ASC",
		"chart": {
		  "type": "area",
		  "config": {
			"xaxis": "time",
			"yaxis": "price",
			"series": "town"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "F2EBMWNXBFRG722XG2MGGV",
		"name": "Year start avg price for a manual list of towns",
		"group": "uk",
		"comment": "",
		"query": "\nSELECT\n    toStartOfYear(date) AS time,\n    district,\n    round(avg(price)) AS price\nFROM uk.uk_price_paid\nWHERE (district IN (\n    SELECT district\n    FROM uk.uk_price_paid\n    WHERE town = 'LONDON'\n    GROUP BY district\n    ORDER BY avg(price) DESC\n    LIMIT 10\n)) AND (district IN ('TOWER HAMLETS', 'HACKNEY', 'NEWHAM', 'CITY OF LONDON', 'WALTHAM FOREST', 'REDBRIDGE', 'BARKING AND DAGENHAM', 'HAVERING', 'HARINGEY', 'EPPING FOREST', 'ISLINGTON', 'CAMDEN', 'CITY OF WESTMINSTER', 'BARNET', 'HARROW', 'HILLINGDON', 'ENFIELD', 'EALING', 'HOUNSLOW', 'HAMMERSMITH AND FULHAM', 'LEWISHAM', 'BRENT', 'WANDSWORTH', 'SOUTHWARK', 'LAMBETH', 'GREENWICH', 'KENSINGTON AND CHELSEA', 'MERTON', 'BROMLEY', 'RICHMOND UPON THAMES', 'CROYDON', 'BEXLEY', 'KINGSTON UPON THAMES', 'HARLOW', 'SUTTON', 'CITY OF BRISTOL', 'MALVERN HILLS', 'THURROCK', 'RHONDDA CYNON TAFF'))\nGROUP BY\n    time,\n    district\nORDER BY time ASC",
		"chart": {
		  "type": "area",
		  "config": {
			"xaxis": "time",
			"yaxis": "price",
			"series": "district"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "8VHKVFS4NZFQGTZNKOWTH1",
		"name": "Year start avg price for all towns with simple condition",
		"group": "uk",
		"comment": "",
		"query": "SELECT\n    toStartOfYear(date) AS time,\n    district,\n    round(avg(price)) AS price\nFROM uk.uk_price_paid\nWHERE (district IN (\n    SELECT district\n    FROM uk.uk_price_paid\n    WHERE uk.uk_price_paid.town = 'LONDON'\n    GROUP BY district\n    ORDER BY avg(price) DESC\n    LIMIT 10\n)) AND (1 = 1)\nGROUP BY\n    time,\n    district\nORDER BY time ASC",
		"chart": {
		  "type": "area",
		  "config": {
			"xaxis": "time",
			"yaxis": "price",
			"series": "district"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "MH8X8UBKWAEPZJD7JHA1RH",
		"name": "Count all rows",
		"group": "noaa",
		"comment": "",
		"query": "SELECT count() FROM noaa.noaa;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GIKBNUA8S14RNEJ2SXU4IJ",
		"name": "Highest temperature in Portugal",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    tempMax / 10 AS maxTemp,\n    station_id,\n    date,\n    location\nFROM noaa.noaa\nWHERE substring(station_id, 1, 2) = 'PO'\nORDER BY tempMax DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "61NDTT5XYXTZEBTVKMN5W2",
		"name": "Highest temperature in Portugal using subquery",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    tempMax / 10 AS maxTemp,\n    station_id,\n    date,\n    location,\n    name\nFROM noaa.noaa\nWHERE station_id IN (\n    SELECT station_id\n    FROM noaa.stations\n    WHERE country_code = 'PO'\n)\nORDER BY tempMax DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "W7QQFHSZVARIBM8FLCJFJF",
		"name": "Highest temperature in Portugal using Joins",
		"group": "noaa",
		"comment": "This query is not optimized and can not be executed due to memory limit quota",
		"query": "SELECT\n    tempMax / 10 AS maxTemp,\n    station_id,\n    date,\n    stations.name AS name,\n    (stations.lat, stations.lon) AS location\nFROM noaa.noaa\nINNER JOIN noaa.stations ON noaa.station_id = stations.station_id\nWHERE stations.country_code = 'PO'\nORDER BY tempMax DESC\nLIMIT 5\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "CSFKIYZ88AJGRHVNXRYYI3",
		"name": "Select one entry from dict",
		"group": "noaa",
		"comment": "",
		"query": "SELECT dictGet(noaa.stations_dict, 'state', 'CA00116HFF6')",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "2APN6W2QFMGF4EVYIMWCC3",
		"name": "Highest temperature in Portugal using dictionary unoptimized",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    tempMax / 10 AS maxTemp,\n    station_id,\n    date,\n    (dictGet('noaa.stations_dict', 'lat', station_id), dictGet('noaa.stations_dict', 'lon', station_id)) AS location,\n    dictGet('noaa.stations_dict', 'name', station_id) AS name\nFROM noaa.noaa\nWHERE station_id IN (\n    SELECT station_id\n    FROM noaa.stations\n    WHERE country_code = 'PO'\n)\nORDER BY tempMax DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "NJM1DPH69PXZYW6XA5TUKX",
		"name": "Highest temperature in Portugal using dictionary optimized",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    tempMax / 10 AS maxTemp,\n    station_id,\n    date,\n    (dictGet('noaa.stations_dict', 'lat', station_id), dictGet('noaa.stations_dict', 'lon', station_id)) AS location,\n    dictGet('noaa.stations_dict', 'name', station_id) AS name\nFROM noaa.noaa\nWHERE dictGet('noaa.stations_dict', 'country_code', station_id) = 'PO'\nORDER BY tempMax DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "T7DVXL4IRQSYDZXUZEMYOL",
		"name": "Weather events in the United States",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    week,\n    toYear(week) AS year,\n    lat, lon,\n    avg_precipitation,\n    max_wind_speed * 10\nFROM\n(\n    SELECT\n        geoHash,\n        week,\n        geohashDecode(geoHash) AS lonlat,\n        lonlat.1 AS lon,\n        lonlat.2 AS lat,\n        max(maxWindSpeed) AS max_wind_speed,\n        avg(precipitation)/10 AS avg_precipitation\n    FROM noaa.noaa\n    WHERE (dictGet(country.country_polygons, 'name', location) IN ('United States of America')) AND (elevation < 500) AND toMonth(date) BETWEEN 6 AND 10\n    GROUP BY\n        geohashEncode(location.1, location.2, 4) AS geoHash,\n        toStartOfWeek(date) AS week\n    HAVING max_wind_speed > 300  AND avg_precipitation > 20      \n    ORDER BY\n        max_wind_speed DESC\n)\nORDER BY\n    year ASC,\n    max_wind_speed DESC\nLIMIT 2 BY year",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "HKEUQL4GMCRQCMTLKDFM6I",
		"name": "Get two states",
		"group": "noaa",
		"comment": "",
		"query": "SELECT *\nFROM noaa.states\nLIMIT 2",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GQVMWG2TB9VOFJPBRXCRPZ",
		"name": "Top ski resorts by amount of snow",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    resort_name,\n    total_snow / 1000 AS total_snow_m,\n    resort_location,\n    month_year\nFROM\n(\n    SELECT\n        resort_name,\n        highest_snow.station_id,\n        geoDistance(lon, lat, station_location.1, station_location.2) / 1000 AS distance_km,\n        highest_snow.total_snow,\n        station_location,\n        month_year,\n        (lon, lat) AS resort_location\n    FROM\n    (\n        SELECT\n            sum(snowfall) AS total_snow,\n            station_id,\n            any(location) AS station_location,\n            month_year,\n            substring(station_id, 1, 2) AS code\n        FROM noaa.noaa\n        WHERE (date > '2017-01-01') AND (code = 'US') AND (elevation > 1800)\n        GROUP BY\n            station_id,\n            toYYYYMM(date) AS month_year\n        ORDER BY total_snow DESC\n        LIMIT 1000\n    ) AS highest_snow\n    INNER JOIN noaa.resorts ON highest_snow.code = resorts.code\n    WHERE distance_km < 20\n    ORDER BY\n        resort_name ASC,\n        total_snow DESC\n    LIMIT 1 BY\n        resort_name,\n        station_id\n)\nORDER BY total_snow DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JTSQ6ZMB8QTXWBFRKPD3J2",
		"name": "Top ski resorts by amount of snow using dictionary",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    resort_name,\n    total_snow / 1000 AS total_snow_m,\n    resort_location,\n    month_year\nFROM\n(\n    SELECT\n        resort_name,\n        highest_snow.station_id,\n        geoDistance(resorts_dict.lon, resorts_dict.lat, station_lon, station_lat) / 1000 AS distance_km,\n        highest_snow.total_snow,\n        (resorts_dict.lon, resorts_dict.lat) as resort_location,\n        month_year\n    FROM\n    (\n        SELECT\n            sum(snowfall) AS total_snow,\n            station_id,\n            dictGet('noaa.stations_dict', 'lat', station_id) AS station_lat,\n            dictGet('noaa.stations_dict', 'lon', station_id) AS station_lon,\n            month_year,\n            dictGet('noaa.stations_dict', 'state', station_id) AS state\n        FROM noaa.noaa\n        WHERE (date > '2017-01-01') AND (state != '') AND (elevation > 1800)\n        GROUP BY\n            station_id,\n            toYYYYMM(date) AS month_year\n        ORDER BY total_snow DESC\n        LIMIT 1000\n    ) AS highest_snow\n    INNER JOIN noaa.resorts_dict ON highest_snow.state = resorts_dict.state\n    WHERE distance_km < 20\n    ORDER BY\n        resort_name ASC,\n        total_snow DESC\n    LIMIT 1 BY resort_name, station_id\n)\nORDER BY total_snow DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "HNQECUKC2F4GGRKHXWRTGS",
		"name": "World's coldest countries",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    code,\n    min(tempMin) / 10 AS min_temp\nFROM noaa.noaa\nWHERE date > '1970-01-01'\nGROUP BY substring(station_id, 1, 2) AS code\nLIMIT 1000",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "DN1SAY1IIIEAWRPF4JHFCG",
		"name": "Find areas with best holidays conditions",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    geoHash,\n    month,\n    avg(percentDailySun) AS avg_daily_sun,\n    geohashDecode(geoHash) AS lonlat,\n    lonlat.1 AS lon,\n    lonlat.2 AS lat,\n    avg(tempAvg) / 10 AS avg_temp,\n    max(tempMax) / 10 AS max_temp,\n    min(tempMin) / 10 AS min_temp,\n    sum(precipitation) AS sum_precipitation,\n    avg(elevation) AS avg_elevation\nFROM noaa.noaa\nWHERE date > '1970-01-01'\nGROUP BY\n    geohashEncode(location.1, location.2, 4) AS geoHash,\n    toMonth(date) AS month\nHAVING (max_temp < 40) AND (min_temp > 0) AND (avg_temp > 10) AND (sum_precipitation < 100) AND (avg_elevation < 1000)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9MFVCCCQDPMXAB6TMG6LQZ",
		"name": "Group locations per temperature conditions",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    values.1 AS labels,\n    values.2 AS count\nFROM\n(\n    SELECT arrayJoin([('not_too_cold', countIf(min_temp > 0)), ('not_too_cold_or_cold', countIf((min_temp > 0) AND (max_temp < 40))), ('ideal_temp', countIf((max_temp < 40) AND (min_temp > 0) AND (avg_temp > 10))), ('ideal_temp_min_rain', countIf((max_temp < 40) AND (min_temp > 0) AND (avg_temp > 10) AND (sum_precipitation < 100))), ('ideal_temp_min_rain_not_high', countIf((max_temp < 40) AND (min_temp > 0) AND (avg_temp > 10) AND (sum_precipitation < 100) AND (avg_elevation < 1000)))]) AS values\n    FROM\n    (\n        SELECT\n            geoHash,\n            month,\n            avg(percentDailySun) AS avg_daily_sun,\n            geohashDecode(geoHash) AS lonlat,\n            lonlat.1 AS lat,\n            lonlat.2 AS lon,\n            avg(tempAvg) / 10 AS avg_temp,\n            max(tempMax) / 10 AS max_temp,\n            min(tempMin) / 10 AS min_temp,\n            sum(precipitation) AS sum_precipitation,\n            avg(elevation) AS avg_elevation\n        FROM noaa.noaa\n        WHERE date > '1970-01-01'\n        GROUP BY\n            geohashEncode(location.1, location.2, 4) AS geoHash,\n            toMonth(date) AS month\n    )\n)",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "day",
			"yaxis": "change"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9IZCFAXDJXUUZTFM1E2H6S",
		"name": "Columns size - Codec V1",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    name,\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_v1'\nGROUP BY name\nORDER BY sum(data_compressed_bytes) DESC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "HKYQD4RDKKTMPGJ4JDOCTU",
		"name": "Columns size - Codec V2",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    name,\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_v2'\nGROUP BY name\nORDER BY sum(data_compressed_bytes) DESC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "MBYL39M5R5OXUB6OHKKC7Q",
		"name": "Columns size - Codec V3",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    name,\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_v3'\nGROUP BY name\nORDER BY sum(data_compressed_bytes) DESC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "DSWEF4PNB6GSGXVHGQB3OS",
		"name": "Columns size - Codec V4",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    name,\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_v4'\nGROUP BY name\nORDER BY sum(data_compressed_bytes) DESC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "QJSXJHRRSDPNHK7OQKHNDJ",
		"name": "Columns size - Codec optimal",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    name,\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_optimal'\nGROUP BY name\nORDER BY sum(data_compressed_bytes) DESC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BUXPNOJD2BMPNLR4KXSGMB",
		"name": "Most effective codec per column",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    name,\n    if(argMin(compression_codec, data_compressed_bytes) != '', argMin(compression_codec, data_compressed_bytes), 'DEFAULT') AS best_codec,\n    formatReadableSize(min(data_compressed_bytes)) AS compressed_size\nFROM system.columns\nWHERE table LIKE 'noaa_codec%'\nGROUP BY name",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "4V8I2PE4TVXENP7JUUJTZ9",
		"name": "Table size - Codec V1",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_v1'",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "RUFWKLMGR4VGVBTTDLY4IQ",
		"name": "Table size - Codec V2",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_v2'",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "UVYOSRZVJDNLKZVVKDWBGM",
		"name": "Table size - Codec V3",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_v3'",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "7US7RPFC3PNFZSDEAYKBYJ",
		"name": "Table size - Codec V4",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    sum(data_uncompressed_bytes) / sum(data_compressed_bytes) AS compression_ratio\nFROM system.columns\nWHERE table = 'noaa_codec_v4'",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "X9OZKPJT7GFLZBCSDGYYN6",
		"name": "Table size - Codec optimal",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) AS ratio\nFROM system.columns\nWHERE table = 'noaa_codec_optimal'",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "DRO8ZSB69FH6LFQWA7AS4Z",
		"name": "Weather statistics for elevations every 100m - codec V1",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    elevation_range,\n    uniq(station_id) AS num_stations,\n    max(tempMax) / 10 AS max_temp,\n    min(tempMin) / 10 AS min_temp,\n    sum(precipitation) AS total_precipitation,\n    avg(percentDailySun) AS avg_percent_sunshine,\n    max(maxWindSpeed) AS max_wind_speed,\n    sum(snowfall) AS total_snowfall\nFROM noaa.noaa_codec_v1\nWHERE (date > '1970-01-01') AND (station_id IN (\n    SELECT station_id\n    FROM noaa.stations\n    WHERE country_code = 'US'\n))\nGROUP BY floor(elevation, -2) AS elevation_range\nORDER BY elevation_range ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "7XY7YJF2KWSX5VRZHGSD9U",
		"name": "Min/Max value boundaries",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    COLUMNS('Wind|temp|snow|pre') APPLY min,\n    COLUMNS('Wind|temp|snow|pre') APPLY max\nFROM noaa.noaa",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "EDQSLZ32CKBUWT1QQJ6TWM",
		"name": "Average precipitation per year by country",
		"group": "noaa",
		"comment": "",
		"query": "SELECT year,\n       avg(`precipitation`) AS `avg_precipitation`,\n       dictGet(`country`.`country_iso_codes`, 'name', code) as country\nFROM `noaa`.`noaa_v2`\nWHERE date > '1970-01-01' AND code IN ('AL', 'AN', 'AU', 'BE', 'BO', 'CY', 'DA', 'EI', 'EZ', 'EN', 'FI', 'FR', 'GG', 'GI', 'GK', 'GM',\n'GR', 'HR', 'HU', 'IC', 'IM', 'IT', 'JE', 'LG', 'LH', 'LO', 'LS', 'LU', 'MD', 'MK', 'MN', 'MT', 'NL', 'NO', 'PL', 'PO', 'RO', 'SI', 'SM',\n'SP', 'SW', 'SZ', 'TU', 'UK', 'UP', 'VT')\nGROUP BY toStartOfYear(`date`) AS `year`,\n         substring(station_id, 1, 2) as code\nHAVING avg_precipitation > 0         \nORDER BY country, year ASC\nLIMIT 100000",
		"chart": {
		  "type": "bar",
		  "config": {
			"xaxis": "year",
			"yaxis": "avg_precipitation",
			"series": "country",
			"stack": true
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "HZZD59S222CCIUI7MVW8AR",
		"name": "Show tables in noaa",
		"group": "noaa",
		"comment": "",
		"query": "SHOW TABLES in noaa WHERE name = 'noaa'    ",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "4RNIAAXZVWK2YLFFVGEC1O",
		"name": "Number of station with no precipitation measured",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    countIf(precipitation = 0) AS num_empty,\n    countIf(precipitation > 0) AS num_non_zero,\n    num_empty / (num_empty + num_non_zero) AS ratio\nFROM noaa.noaa",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "XZH9SXO4NNJ5OQ1PITDN5C",
		"name": "Weather statistics for elevations every 100m - codec V3",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    elevation_range,\n    uniq(station_id) AS num_stations,\n    max(tempMax) / 10 AS max_temp,\n    min(tempMin) / 10 AS min_temp,\n    sum(precipitation) AS total_precipitation,\n    avg(percentDailySun) AS avg_percent_sunshine,\n    max(maxWindSpeed) AS max_wind_speed,\n    sum(snowfall) AS total_snowfall\nFROM noaa.noaa_codec_v3\nWHERE (date > '1970-01-01') AND (station_id IN (\n    SELECT station_id\n    FROM noaa.stations\n    WHERE country_code = 'US'\n))\nGROUP BY floor(elevation, -2) AS elevation_range\nORDER BY elevation_range ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "OWCAGSZEFJVH5F6DAHAHVJ",
		"name": "Weather statistics for elevations every 100m - codec optimal",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    elevation_range,\n    uniq(station_id) AS num_stations,\n    max(tempMax) / 10 AS max_temp,\n    min(tempMin) / 10 AS min_temp,\n    sum(precipitation) AS total_precipitation,\n    avg(percentDailySun) AS avg_percent_sunshine,\n    max(maxWindSpeed) AS max_wind_speed,\n    sum(snowfall) AS total_snowfall\nFROM noaa.noaa_codec_optimal\nWHERE (date > '1970-01-01') AND (station_id IN (\n    SELECT station_id\n    FROM noaa.stations\n    WHERE country_code = 'US'\n))\nGROUP BY floor(elevation, -2) AS elevation_range\nORDER BY elevation_range ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GF7GFDIAUKNTGQOFBWLPF6",
		"name": "Highest temperature measured in the world",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    tempMax / 10 AS maxTemp,\n    location,\n    name,\n    date\nFROM noaa.noaa\nORDER BY\n    tempMax DESC,\n    date ASC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JZRNS4M2OVRHBAKDVQNEUQ",
		"name": "Highest temperature measured in each Portuguese region.",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n    tempMax / 10 AS maxTemp,\n    station_id,\n    date,\n    location\nFROM noaa.noaa\nWHERE dictGet(country.country_polygons, 'name', location) = 'Portugal'\nORDER BY tempMax DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "5XPYMUKF7RKCEFCUJWGDPE",
		"name": "Highest temperature measured in each Canadian region",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n   tempMax / 10 AS maxTemp,\n   station_id,\n   date,\n   location\nFROM noaa.noaa\nWHERE dictGet(country.country_polygons, 'name', location) = 'Canada'\nORDER BY tempMax DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "29YQBREOAFP3QZNIARGTQO",
		"name": "Highest temperature measured in Canadian region matching a specific land area",
		"group": "noaa",
		"comment": "",
		"query": "SELECT\n   tempMax / 10 AS maxTemp,\n   station_id,\n   date,\n   location\nFROM noaa.noaa\nWHERE substring(station_id, 1, 2) = 'CA'\nORDER BY tempMax DESC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "NHQIA2R29W9QCV8QL9EPNA",
		"name": "Hottest areas of the United States and Mexico",
		"group": "noaa",
		"comment": "",
		"query": "SELECT geoHash, geohashDecode(geoHash) as lon_lat, max(tempMax)/10 as max_temp\nFROM noaa.noaa\nWHERE date > '1970-01-01' and dictGet(country.country_polygons, 'name', location) IN ('United States of America', 'Mexico')\nGROUP BY geohashEncode(location.1, location.2, 3) as geoHash",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "day",
			"yaxis": "high"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "6B6MXXER1XG8J2QVTY3NMA",
		"name": "Forex table size",
		"group": "forex",
		"comment": "",
		"query": "SELECT\n    table,\n    formatReadableSize(sum(data_compressed_bytes)) AS compressed_size,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS uncompressed_size,\n    sum(data_compressed_bytes) / sum(data_uncompressed_bytes) AS compression_ratio\nFROM system.columns\nWHERE (database = 'forex') AND (table = 'forex')\nGROUP BY table\nORDER BY table ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BXNF4KPUROV9QRCS5FAGMD",
		"name": "Analysis of the GBP/EUR",
		"group": "forex",
		"comment": "",
		"query": "SELECT\n    base,\n    quote,\n    day,\n    close,\n    close - any(close) OVER (PARTITION BY base, quote ORDER BY base ASC, quote ASC, day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS change\nFROM\n(\n    SELECT\n        base,\n        quote,\n        day,\n        argMax(ask, datetime) AS close\n    FROM forex.forex\n    WHERE (quote = 'GBP') AND (base = 'EUR') AND (datetime > '2016-01-01 00:00:00.000') AND (datetime < '2017-01-01 00:00:00.000')\n    GROUP BY\n        base,\n        quote,\n        toStartOfDay(datetime) AS day\n    ORDER BY\n        base ASC,\n        quote ASC,\n        day ASC\n)\nORDER BY\n    base ASC,\n    quote ASC,\n    day ASC",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "day",
			"yaxis": "change"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "NUJZCPYKAMVRNRMWCXZTSY",
		"name": "Get first timestamp for each quotes",
		"group": "forex",
		"comment": "",
		"query": "SELECT\n    base,\n    quote,\n    min(datetime)\nFROM forex.forex_usd\nGROUP BY\n    base,\n    quote",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "RKVF4YKRGPSSNGJ3DACN79",
		"name": "Periods of high spread in the EUR/USD",
		"group": "forex",
		"comment": "",
		"query": "SELECT\n    base,\n    quote,\n    day,\n    spread - any(spread) OVER (PARTITION BY base, quote ORDER BY base ASC, quote ASC, day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS change\nFROM\n(\n    SELECT\n        base,\n        quote,\n        avg(ask - bid) AS spread,\n        day\n    FROM forex.forex\n    WHERE (base = 'EUR') AND (quote = 'USD')\n    GROUP BY\n        base,\n        quote,\n        toYYYYMMDD(datetime) AS day\n    ORDER BY\n        base ASC,\n        quote ASC,\n        day ASC\n)\nORDER BY change DESC\nLIMIT 5\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "FELR1JPYR2UGMNEUC1MTRN",
		"name": "Periods of high change in pairs involving the GBP",
		"group": "forex",
		"comment": "",
		"query": "WITH daily_change AS\n    (\n        SELECT\n            base,\n            quote,\n            day,\n            close,\n            close - any(close) OVER (PARTITION BY base, quote ORDER BY base ASC, quote ASC, day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS change\n        FROM\n        (\n            SELECT\n                base,\n                quote,\n                day,\n                argMax(ask, datetime) AS close\n            FROM forex.forex\n            WHERE (quote = 'GBP') OR (base = 'GBP')\n            GROUP BY\n                base,\n                quote,\n                toStartOfDay(datetime) AS day\n            ORDER BY\n                base ASC,\n                quote ASC,\n                day ASC\n        )\n        ORDER BY\n            base ASC,\n            quote ASC,\n            day ASC\n    )\nSELECT *\nFROM daily_change\nWHERE day > '2016-01-02 00:00:00'\nORDER BY abs(change) DESC\nLIMIT 1 BY\n    base,\n    quote",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "QEB835S62CZDPVTOVPBUH9",
		"name": "USD price against the price of oil",
		"group": "forex",
		"comment": "",
		"query": "SELECT\n    day,\n    argMax(ask, datetime) AS price\nFROM forex.forex\nWHERE (datetime > '2010-01-01 00:00:00') AND (base = 'BCO') AND (quote = 'USD')\nGROUP BY toStartOfDay(datetime) AS day\nORDER BY day ASC",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "day",
			"yaxis": "price"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "VHWZWZ4XWZTFP167AU9JAG",
		"name": "Volatility for a currency pair",
		"group": "forex",
		"comment": "",
		"query": "SELECT\n    day,\n    stddevPop(change) OVER (PARTITION BY base, quote ORDER BY day ASC ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) AS volatility,\n    if(abs(change) > volatility, 'true', 'false') AS volitile\nFROM\n(\n    SELECT\n        base,\n        quote,\n        day,\n        close,\n        close - any(close) OVER (PARTITION BY base, quote ORDER BY base ASC, quote ASC, day ASC ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS change\n    FROM\n    (\n        SELECT\n            base,\n            quote,\n            day,\n            argMax(ask, datetime) AS close\n        FROM forex.forex\n        WHERE (quote = 'USD') AND (base = 'GBP') AND (datetime > '2010-01-01 00:00:00')\n        GROUP BY\n            base,\n            quote,\n            toStartOfDay(datetime) AS day\n        ORDER BY\n            base ASC,\n            quote ASC,\n            day ASC\n    )\n    ORDER BY\n        base ASC,\n        quote ASC,\n        day ASC\n)\nORDER BY\n    base ASC,\n    quote ASC,\n    day ASC",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "day",
			"yaxis": "volatility"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "G5QCEZE3VY4CDVFE7MSIAE",
		"name": "EUR price evolution compared to other pairs",
		"group": "forex",
		"comment": "",
		"query": "SELECT toStartOfDay(datetime) as time, quote, argMax(bid,datetime) as close\nFROM forex.forex\nWHERE (base ='EUR') AND quote IN ('GBP', 'USD', 'NZD', 'CND') AND datetime >= '1464739200' AND datetime <= '1633046400'\nGROUP BY time, quote\nORDER BY time ASC, quote ASC",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "time",
			"yaxis": "close",
			"series": "quote"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "NJPUOAHZYRPELRF6DY2XFT",
		"name": "EUR price evolution against USD",
		"group": "forex",
		"comment": "",
		"query": "SELECT toStartOfDay(datetime) as day, argMin(ask, datetime) as open, argMax(ask,datetime) as close, max(ask) as high, min(ask) as low\nFROM forex.forex\nWHERE (base ='EUR') AND quote ='USD' AND datetime >= '1464739200' AND datetime <= '1633046400'\nGROUP BY day\nORDER BY day ASC",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "day",
			"yaxis": "high"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "VWNMT1VWGJACNVNNPZYMFD",
		"name": "All posts mentioning ClickHouse over time",
		"group": "hackernews",
		"comment": "",
		"query": "SELECT\n    toYYYYMM(toDateTime(time)) AS monthYear,\n    bar(count(), 0, 120, 20) AS count\nFROM hackernews.hackernews\nWHERE (text ILIKE '%ClickHouse%')\nGROUP BY monthYear\nORDER BY monthYear ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JYYNJM7UWYX5RIWU7GPGTJ",
		"name": "Post per month histogram",
		"group": "hackernews",
		"comment": "",
		"query": "SELECT count() as `posts per month`, toStartOfMonth(time) as month FROM hackernews.hackernews WHERE type IN ('comment', 'story') AND (text ILIKE '%ClickHouse%' OR title ILIKE '%ClickHouse%') GROUP BY month ORDER BY month LIMIT 1000",
		"chart": {
		  "type": "bar",
		  "config": {
			"xaxis": "month",
			"yaxis": "posts per month",
			"stack": false
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "PW9DCFW8AWGRHYHHQ7TODQ",
		"name": "Top phrases",
		"group": "hackernews",
		"comment": "",
		"query": "WITH stop_words AS\n   (\n       SELECT token\n       FROM words.stop_words\n   )\nSELECT\n   phrase,\n   count() AS c\nFROM\n(\n   SELECT\n       arrayJoin(shingles) AS shingle,\n       concat(shingle.1, ' ', shingle.2) AS phrase\n   FROM\n   (\n       SELECT\n           tokens,\n           arrayFilter(t -> (NOT ((t.2) IS NULL)), arrayZip(tokens, arrayPushBack(arrayPopFront(tokens), NULL))) AS shingles\n       FROM\n       (\n           SELECT arrayFilter(t -> ((t NOT IN (stop_words)) AND (length(t) > 2)), alphaTokens(title)) AS tokens\n           FROM hackernews.hackernews\n           WHERE (type IN ('story', 'comment'))\n       )\n       \n       WHERE length(tokens) > 0\n   )\n)\nGROUP BY phrase\nORDER BY c DESC\nLIMIT 20",
		"chart": {
		  "type": "horizontal bar",
		  "config": {
			"xaxis": "phrase",
			"yaxis": "c"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "24AZ83BWSK7DYB24TDJHZD",
		"name": "Logs histogram per level",
		"group": "logs",
		"comment": "",
		"query": "SELECT (now() - (toDateTime('1998-05-08 13:44:46') - timestamp)) as log_time,\n       multiIf(message.status > 500, 'critical', message.status > 400, 'error', message.status > 300, 'warning',\n               'info')                                           as level,\n       message.request.method                                    as method,\n       message.status                                            as status,\n       message.size                                              as size,\n       message.request                                           as log\nFROM logs.http_logs\nORDER BY timestamp DESC\nLIMIT 10000",
		"chart": {
		  "type": "bar",
		  "config": {
			"xaxis": "log_time",
			"yaxis": "status",
			"series": "level",
			"stack": true
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "PT6BDKJPNWWYVOSFHJ2N9H",
		"name": "Show logs sample",
		"group": "logs",
		"comment": "",
		"query": "SELECT * FROM logs.http_logs LIMIT 10    \n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "3ZBX6XXPDY7TNOP7QOWHAB",
		"name": "Show parity",
		"group": "numbers",
		"comment": "",
		"query": "SELECT\n    number,\n    parity_str(number)\nFROM numbers(5)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "SBUUEETHAQ5F2G22N83N5O",
		"name": "SELECT randCanonical",
		"group": "random",
		"comment": "",
		"query": "SELECT randCanonical()",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "4NBCMXTYTA9YTCCZLQVXAX",
		"name": "SELECT randUniform",
		"group": "random",
		"comment": "",
		"query": "SELECT randUniform(5,10)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "J6DVNJWSXSQS5GRDTRMPLH",
		"name": "SELECT randUniform",
		"group": "random",
		"comment": "",
		"query": "SELECT floor(randUniform(5, 10)) AS r\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "QK3XFPOY1ENJWTGI3OV6W2",
		"name": "SELECT randNormal",
		"group": "random",
		"comment": "",
		"query": "SELECT randNormal(100, 5)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BZU8EGF4FDZWQ7WJYHEVG8",
		"name": "Visualize randNormal",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randNormal(100, 5)) AS k,\n    count(*) AS c,\n    bar(c, 0, 50000, 100)\nFROM numbers(100000) GROUP BY k ORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "WPE9ESMN2DUMV1VXDNYFGG",
		"name": "Visualize randBinomial",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randBinomial(100, 0.85)) AS k,\n    bar(count(*), 0, 50000, 100) AS b1\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "F22WJVPWARLKMGDIV1MSX3",
		"name": "Visualize randNegativeBinomial",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randNegativeBinomial(100, 0.85)) AS k,\n    bar(count(*), 0, 50000, 100) AS b1\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "89WD1BCBQH3CDS1PJW2RST",
		"name": "Visualize randLogNormal",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randLogNormal(1 / 100, 0.75)) AS k,\n    bar(count(*), 0, 50000, 10) AS b1\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JZFQ4QXNR496JRBSYWQZFX",
		"name": "Visualize randExponential",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randExponential(1 / 2)) AS k,\n    bar(count(*), 0, 50000, 10) AS b1\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "68A57FHXKATFL3BPRZSXPX",
		"name": "Visualize randChiSquared",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randChiSquared(10)) AS k,\n    bar(count(*), 0, 10000, 10) AS b1\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "RXS6OCJLLIW8F3YAMHYECY",
		"name": "Visualize randStudentT",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randStudentT(4.5)) AS k,\n    bar(count(*), 0, 10000, 10) AS b1\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "W68QKVQ8SRT4QCJMVK3X6T",
		"name": "Visualize randFisherF",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randFisherF(3, 20)) AS k,\n    bar(count(*), 0, 10000, 10) AS b1\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "FABP4BRNHNFQGE9JJBWZNF",
		"name": "Visualize randPoisson",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randPoisson(10)) AS k,\n    bar(count(*), 0, 15000, 10) AS b1\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "UUUNYD3J4X9MU3R1HZSFPG",
		"name": "Visualize randBernoulli",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(randBernoulli(0.75)) AS k,\n    count(*)\nFROM numbers(100000)\nGROUP BY k\nORDER BY k ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "TGPZRLB1RMKOUS6ZTFQHRT",
		"name": "Total spent distribution",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    floor(total_spent) AS s,\n    count(*) AS n,\n    bar(n, 0, 350000, 50)\nFROM random.purchases\nGROUP BY s\nORDER BY s ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "1UU1ECB2IZWLCGULVAJMJM",
		"name": "Click events distribution",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    toStartOfHour(dt) AS hour,\n    count(*) AS c,\n    bar(c, 0, 15000, 50)\nFROM random.events\nGROUP BY hour\nORDER BY hour ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JMDKIGQJRSLZYLTAVKAWNA",
		"name": "CPU load hourly distribution ",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    toStartOfHour(dt) AS h,\n    round(avg(val), 2) AS v,\n    bar(v, 0, 100)\nFROM random.metrics\nGROUP BY h\nORDER BY h ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "EKHAVPH67P9XQHJPFQWVHO",
		"name": "Select randBernoulli",
		"group": "random",
		"comment": "",
		"query": "SELECT randBernoulli(0.9)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "J1A8SOEHBGZVTLSRKJVB7W",
		"name": "Simulate binary state",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    If(randBernoulli(0.95), 'success', 'failure') AS status,\n    count(*) AS c\nFROM numbers(1000)\nGROUP BY status",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "FPTERBSNQFQ21TDQGTMAAR",
		"name": "Random HTTP codes",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    ['200', '404', '502', '403'][toInt32(randBinomial(4, 0.1)) + 1] AS http_code,\n    count(*)\nFROM numbers(1000)\nGROUP BY http_code\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "BCIAZ32CS95NFRP3XZ3ZPM",
		"name": "Random strings",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    randomPrintableASCII(randUniform(5, 25)) AS s,\n    length(s) as length    \nFROM numbers(10)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "X7G6ZEFF4LVDKCZBH5GPMD",
		"name": "Generate noisy data",
		"group": "random",
		"comment": "",
		"query": "SELECT fuzzBits('Good string', 0.01)\nFROM numbers(10)\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "4YGUG8FWTWZELB7DRG2GQY",
		"name": "Detect generated faulty strings",
		"group": "random",
		"comment": "",
		"query": "SELECT\n    IF(fuzzBits('Good string', 0.001) = 'Good string', 1, 0) AS has_errors,\n    count(*)\nFROM numbers(1000)\nGROUP BY has_errors",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "3H7CREOQQNO6TXGRPGB3QN",
		"name": "RandNormal distribution of clicks",
		"group": "random",
		"comment": "",
		"query": "\nSELECT\n    dt,\n    count(*) AS c,\n    bar(c, 0, 100000)\nFROM random.click_events\nGROUP BY dt\nORDER BY dt ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GEFQJZTCMQPSB8ZMDCHJWK",
		"name": "Show create table hits",
		"group": "metrica",
		"comment": "",
		"query": "SHOW CREATE TABLE metrica.hits",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "537DNRRQ1XJBOTNA9UXWPA",
		"name": "Total amount of hits for each day",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    sum(hits) AS h,\n    toDate(time) AS d\nFROM wiki.wikistat_small\nGROUP BY d\nORDER BY d\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9GJNUGQSWRRPZRPMFVD2DU",
		"name": "Total amount of hits for each hour",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    sum(hits) AS v,\n    toStartOfHour(time) AS h\nFROM wiki.wikistat_small\nWHERE date(time) = '2015-05-01'\nGROUP BY h\nORDER BY h ASC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "7HPC3EXF1K3CCFEZGJ36XT",
		"name": "Total amount of hits by 4-hour intervals",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    sum(hits) AS v,\n    toStartOfInterval(time, toIntervalHour(4)) AS h\nFROM wiki.wikistat_small\nWHERE date(time) = '2015-05-01'\nGROUP BY h\nORDER BY h ASC\nLIMIT 6",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "AWOMAV5AQUHFUHVXZ5UGDR",
		"name": "Total amount of hits for each hour with missing intervals",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    toStartOfHour(time) AS h,\n    sum(hits)\nFROM wiki.wikistat_small\nWHERE (project = 'it') AND (subproject = 'm') AND (date(time) = '2015-06-12')\nGROUP BY h\nORDER BY h ASC\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "PUNOYTV9U37JUHQHDBK1RB",
		"name": "Total amount of hits for each hour with filled intervals",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    toStartOfHour(time) AS h,\n    sum(hits)\nFROM wiki.wikistat_small\nWHERE (project = 'it') AND (subproject = 'm') AND (date(time) = '2015-06-12')\nGROUP BY h\nORDER BY h ASC WITH FILL STEP toIntervalHour(1)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "NT9TMF54T6ZD6EIJOQSWSQ",
		"name": "Rolling time window",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    sum(hits),\n    dateDiff('day', toDateTime('2015-05-01 18:00:00'), toDateTime(time)) AS d\nFROM wiki.wikistat_small\nGROUP BY d\nORDER BY d ASC\nLIMIT 5",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "7FM7GEM6MGK3I4Y916BRKK",
		"name": "Visualize the most and least popular hours in terms of page views",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    toHour(time) AS h,\n    sum(hits) AS t,\n    bar(t, 0, max(t) OVER ())\nFROM wiki.wikistat_small\nGROUP BY h\nORDER BY h ASC",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "JAEWDDPZHMJOVSZEDD3RVB",
		"name": "Distribution of a number of pages based on their total hits",
		"group": "wiki",
		"comment": "",
		"query": "WITH histogram(10)(hits) AS h\nSELECT\n    round(arrayJoin(h).1) AS l,\n    round(arrayJoin(h).2) AS u,\n    arrayJoin(h).3 AS w,\n    bar(w, 0, max(w) OVER (), 20) AS b\nFROM\n(\n    SELECT\n        path,\n        sum(hits) AS hits\n    FROM wiki.wikistat_small\n    WHERE date(time) = '2015-06-15'\n    GROUP BY path\n    HAVING hits > 10000.\n)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "5GDTHIPSNWHKXN1KUSQSMJ",
		"name": "Daily hits for a given page",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    toDate(time) AS d,\n    sum(hits) AS h,\n    lagInFrame(h) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS p,\n    h - p AS trend\nFROM wiki.wikistat_small\nWHERE path = 'Bob'\nGROUP BY d\nORDER BY d ASC\nLIMIT 15",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "CRHBCIOY1ZKMX6ZK7DXG7Z",
		"name": "Page cumulative growth",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    toDate(time) AS d,\n    sum(hits) AS h,\n    sum(h) OVER (ROWS BETWEEN UNBOUNDED PRECEDING AND 0 FOLLOWING) AS c,\n    bar(c, 0, 3200000, 25) AS b\nFROM wiki.wikistat_small\nWHERE path = 'Bob'\nGROUP BY d\nORDER BY d ASC\nLIMIT 15",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "XQVSQGEZEZUZUAQURVO8VZ",
		"name": "Hit rate per second for a given date grouped by hours",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    toStartOfHour(time) AS t,\n    sum(hits) AS h,\n    round(h / (60 * 60), 2) AS rate,\n    bar(rate * 10, 0, max(rate * 10) OVER (), 25) AS b\nFROM wiki.wikistat_small\nWHERE path = 'Bob'\nGROUP BY t\nORDER BY t ASC\nLIMIT 23",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "G7YRTCRZ7RJPMTZCRFCPDB",
		"name": "Number of projects",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    uniq(project),\n    uniq(subproject)\nFROM wiki.wikistat_small",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "DE5AJMQ3DLWAPSOJP1PI9C",
		"name": "Select max hits",
		"group": "wiki",
		"comment": "",
		"query": "SELECT max(hits)\nFROM wiki.wikistat_small",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "HPGEZK7USHGDUGTJTHJAYV",
		"name": "Sum hits per project",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    project,\n    sum(hits) AS h\nFROM wiki.wikistat_small\nGROUP BY project\nORDER BY h DESC\nLIMIT 10\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GFCCTYVJ3YVGMTOFXDQZJT",
		"name": "Sum hits per project - Optimized",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    project,\n    sum(hits) AS h\nFROM wiki.optimized_wikistat_small\nGROUP BY project\nORDER BY h DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "2Q8G2SWXOOSHHVVBQB8ND2",
		"name": "Sum hits per sub-project",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    subproject,\n    sum(hits) AS h\nFROM wiki.wikistat_small\nWHERE project = 'it'\nGROUP BY subproject\nORDER BY h DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "1G21SEVPJZM1XFRTPR6MVR",
		"name": "Sum hits per sub-project - Optimized",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    subproject,\n    sum(hits) AS h\nFROM wiki.optimized_wikistat_small\nWHERE project = 'it'\nGROUP BY subproject\nORDER BY h DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "4TB6QY6HMELIW5PUWRNG4M",
		"name": "Sum hits for a specific project and sub-project",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    toStartOfMonth(time) AS m,\n    sum(hits) AS h\nFROM wiki.wikistat_small\nWHERE (project = 'it') AND (subproject = 'zero')\nGROUP BY m\nORDER BY m DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9EBNNA5MNGKSDJMNLGMCHB",
		"name": "Sum hits for a specific project and sub-project - Optimized",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    toStartOfMonth(time) AS m,\n    sum(hits) AS h\nFROM wiki.optimized_wikistat_small\nWHERE (project = 'it') AND (subproject = 'zero')\nGROUP BY m\nORDER BY m DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "WW6JBMONCU5VKCKQXSYTFM",
		"name": "Sum hits for a specific project and sub-project ordered by path",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    path,\n    sum(hits) AS h\nFROM wiki.wikistat_small\nWHERE (project = 'it') AND (subproject = 'zero')\nGROUP BY path\nORDER BY h DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "3EYNNE9LVWLHSAH2MD4N3Y",
		"name": "Sum hits for a specific project and sub-project ordered by path - Optimized",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    path,\n    sum(hits) AS h\nFROM wiki.optimized_wikistat_small\nWHERE (project = 'it') AND (subproject = 'zero')\nGROUP BY path\nORDER BY h DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "PSZHGXKFFDGDRADCAMCF1Q",
		"name": "Top path using materialized views",
		"group": "wiki",
		"comment": "",
		"query": "SELECT\n    path,\n    hits\nFROM wiki.wikistat_top\nWHERE month = '2015-05-01'\nORDER BY hits DESC\nLIMIT 10",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "5RZTNTHWWQKVMZHBTXSRG2",
		"name": "Select view search_clickhouse_stackoverflow",
		"group": "stackoverflow",
		"comment": "",
		"query": "SELECT *\nFROM stackoverflow.search_clickhouse_stackoverflow",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "OVVFRFJVZXTWGQDB2CQDU7",
		"name": "Search post mentioning ClickHouse MergeTree",
		"group": "stackoverflow",
		"comment": "",
		"query": "SELECT *\nFROM stackoverflow.search_stackoverflow(text = 'ClickHouse MergeTree')\nORDER BY Score DESC\nLIMIT 1",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "AACTS8ZBT3G7SSGN8ZJBJY",
		"name": "Show tables",
		"group": "imdb",
		"comment": "",
		"query": "SHOW TABLES FROM imdb;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "SXBYSHJHMVZQTTA8NJFXIJ",
		"name": "Fnds the genre for each movie",
		"group": "imdb",
		"comment": "",
		"query": "SELECT\n    m.name AS name,\n    g.genre AS genre\nFROM imdb.movies AS m\nINNER JOIN imdb.genres AS g ON m.id = g.movie_id\nORDER BY\n    m.year DESC,\n    m.name ASC,\n    g.genre ASC\nLIMIT 10;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "ULZ1D3RO8UIJ7OGNEWFPJJ",
		"name": "Finds all movies with no genre",
		"group": "imdb",
		"comment": "",
		"query": "SELECT m.name\nFROM imdb.movies AS m\nLEFT JOIN imdb.genres AS g ON m.id = g.movie_id\nWHERE g.movie_id = 0\nORDER BY\n    m.year DESC,\n    m.name ASC\nLIMIT 10;",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "IGYXD5K3FHANTAEFSXFRNZ",
		"name": "Cross joins movie and genre tables",
		"group": "imdb",
		"comment": "",
		"query": "SELECT\n    m.name,\n    m.id,\n    g.movie_id,\n    g.genre\nFROM imdb.movies AS m\nCROSS JOIN imdb.genres AS g\nLIMIT 10;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "ITEJZPXTD1CNGRAZHVBJUY",
		"name": "Finds the genre for each movie using Cross joins",
		"group": "imdb",
		"comment": "",
		"query": "SELECT\n    m.name,\n    g.genre\nFROM imdb.movies AS m\nCROSS JOIN imdb.genres AS g\nWHERE m.id = g.movie_id\nORDER BY\n    m.year DESC,\n    m.name ASC\nLIMIT 10;\n\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "P8JVPYHHCSWLTAY1JCSZXQ",
		"name": "Cross joins explain",
		"group": "imdb",
		"comment": "",
		"query": "EXPLAIN SYNTAX\nSELECT\n    m.name AS name,\n    g.genre AS genre\nFROM imdb.movies AS m\nCROSS JOIN imdb.genres AS g\nWHERE m.id = g.movie_id\nORDER BY\n    m.year DESC,\n    m.name ASC,\n    g.genre ASC\nLIMIT 10;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "2T1SYGUTWFFZBW7EEZQB3F",
		"name": "Finds all persons that performed in a movie in 2023",
		"group": "imdb",
		"comment": "",
		"query": "SELECT\n    a.first_name,\n    a.last_name\nFROM imdb.actors AS a\nLEFT SEMI JOIN imdb.roles AS r ON a.id = r.actor_id\nWHERE toYear(created_at) = '2023'\nORDER BY id ASC\nLIMIT 10;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "3R1AT8GC5S4JHPZSGKC6K4",
		"name": "Find movie with no genre using anti join",
		"group": "imdb",
		"comment": "",
		"query": "SELECT m.name\nFROM imdb.movies AS m\nLEFT ANTI JOIN imdb.genres AS g ON m.id = g.movie_id\nORDER BY\n    year DESC,\n    name ASC\nLIMIT 10;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "TJQUE4JPEWUPWVV8RYWBTA",
		"name": "LEFT ANY JOIN example",
		"group": "join",
		"comment": "",
		"query": "WITH\n    left_table AS (SELECT * FROM VALUES('c UInt32', 1, 2, 3)),\n    right_table AS (SELECT * FROM VALUES('c UInt32', 2, 2, 3, 3, 4))\nSELECT\n    l.c AS l_c,\n    r.c AS r_c\nFROM left_table AS l\nLEFT ANY JOIN right_table AS r ON l.c = r.c;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "OYVCDZYVGI7LFDAAZJ8DQG",
		"name": "RIGHT ANY JOIN example",
		"group": "join",
		"comment": "",
		"query": "WITH\n    left_table AS (SELECT * FROM VALUES('c UInt32', 1, 2, 3)),\n    right_table AS (SELECT * FROM VALUES('c UInt32', 2, 2, 3, 3, 4))\nSELECT\n    l.c AS l_c,\n    r.c AS r_c\nFROM left_table AS l\nRIGHT ANY JOIN right_table AS r ON l.c = r.c;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "GJMMKQZX1UTRFW6MZSAYCH",
		"name": "INNER ANY JOIN example",
		"group": "join",
		"comment": "",
		"query": "WITH\n    left_table AS (SELECT * FROM VALUES('c UInt32', 1, 2, 3)),\n    right_table AS (SELECT * FROM VALUES('c UInt32', 2, 2, 3, 3, 4))\nSELECT\n    l.c AS l_c,\n    r.c AS r_c\nFROM left_table AS l\nINNER ANY JOIN right_table AS r ON l.c = r.c;\n",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9WOMEAY1CFZUVQN6DZXRY7",
		"name": "Show formats",
		"group": "system",
		"comment": "",
		"query": "SELECT *\nFROM system.formats",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "MNVFKT7APRSXKVDVQYM5JB",
		"name": "Show table engines",
		"group": "system",
		"comment": "",
		"query": "SELECT *\nFROM system.table_engines",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "IQPQW45RJGWDCV66FT4D6T",
		"name": "Show functions",
		"group": "system",
		"comment": "",
		"query": "SELECT *\nFROM system.functions\nWHERE origin = 'System'",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "9RNS3C9SDFSCDV2AOXW8A6",
		"name": "Show function per category",
		"group": "system",
		"comment": "",
		"query": "WITH both AS (\n        SELECT name, 'Table function' as category\n        FROM system.table_functions \n    UNION ALL\n        SELECT name, 'Table engine' as category\n        FROM system.table_engines\n)\nSELECT * \nFROM both\nWHERE \n    NOT name ilike '%mergeTree%' AND\n    NOT name ilike '%view%' AND\n    NOT name ilike '%values%' AND\n    NOT name ilike '%zeros%' AND\n    NOT name ilike '%cosn%' AND\n    NOT name ilike '%cosn%' AND\n    NOT name ilike '%buffer%' AND\n    NOT name ilike '%replica%' AND\n    NOT name ilike '%distributed%' AND\n    NOT name ilike '%json%' AND\n    NOT name ilike '%random%' AND\n    NOT name ilike '%merge%'AND\n    NOT name ilike '%null%'AND\n    NOT name ilike '%numbers%'AND\n    NOT name ilike '%oss%'AND\n    NOT name IN ['cluster', 'format', 'input', 'Join', 'KeeperMap', 'Log', 'Memory', 'Set', 'StripeLog', 'TinyLog']    \nORDER BY lower(name)",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "4MGH76GE6QN6WA6H8TCYKR",
		"name": "Top 10 busiest stations in 2018",
		"group": "mta",
		"comment": "",
		"query": "SELECT station, sum(entries_change) as total_entries, formatReadableQuantity(total_entries) as total_entries_read\nFROM mta.subway_transits_2014_2022_v2\nWHERE toYear(date_time) = '2018'\nGROUP BY station \nORDER BY sum(entries_change) DESC\nLIMIT 10",
		"chart": {
		  "type": "bar",
		  "config": {
			"xaxis": "station",
			"yaxis": "total_entries",
			"series": "station",
			"stack": true
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "KADCUSBZG3UWVV2N4QUJXW",
		"name": "Change in traffic over the years for busiest station",
		"group": "mta",
		"comment": "",
		"query": "SELECT\n  station,\n  toYear(date_time) as year,\n  sum(entries_change) as total_entries\nFROM\n  mta.subway_transits_2014_2022_v2\nWHERE\n  station IN (\n    SELECT station FROM mta.subway_transits_2014_2022_v2 GROUP BY station ORDER BY sum(entries_change) DESC LIMIT 10\n  )\nGROUP BY\n  year,\n  station\nORDER BY\n  year\n",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "year",
			"yaxis": "total_entries",
			"series": "station",
			"stack": false
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "STHDUVXOFZFGF2JCHJGB5Y",
		"name": "Traffic comparison weekdays versus weekend",
		"group": "mta",
		"comment": "",
		"query": "SELECT\n    toStartOfWeek(transit_timestamp) as week,\n    'weekday' as period,\n    sum(ridership) AS total\nFROM mta.transit_data WHERE toDayOfWeek(transit_timestamp) <= 5\nGROUP BY week ORDER BY week ASC\nUNION ALL\nSELECT\n    toStartOfWeek(transit_timestamp) as week,\n    'weekend' as period,\n    sum(ridership) AS total\nFROM mta.transit_data WHERE toDayOfWeek(transit_timestamp) > 5\nGROUP BY week ORDER BY week ASC",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "week",
			"yaxis": "total",
			"series": "period"
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "HPN5AHXEHK1NM2NB9S3AV2",
		"name": "Average hourly traffic by hour of the day",
		"group": "mta",
		"comment": "",
		"query": "SELECT\n    station_complex, toHour(hour_of_day) as hour, avg(total_entries):: UInt64 AS avg_entries\nFROM\n(\n    SELECT\n        toStartOfHour(transit_timestamp) AS hour_of_day,\n        station_complex,\n        sum(ridership) AS total_entries\n    FROM mta.transit_data WHERE toDayOfWeek(transit_timestamp) <= 5\n    GROUP BY\n        station_complex,\n        hour_of_day\n)\nGROUP BY hour, station_complex ORDER BY hour ASC, avg_entries DESC LIMIT 3 BY hour",
		"chart": {
		  "type": "bar",
		  "config": {
			"xaxis": "hour",
			"yaxis": "avg_entries",
			"series": "station_complex",
			"stack": true
		  }
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "7VVBISZSVYWTAWR8LUDSTE",
		"name": "Sample tweets from a specific user",
		"group": "twitter",
		"comment": "",
		"query": "SELECT created_at, text FROM twitter.twitter WHERE tupleElement(user, 'screen_name') = 'elonmusk' ORDER BY created_at",
		"chart": {
		  "type": "line"
		},
		"format": false,
		"params": []
	  },
	  {
		"id": "ASSNFTKPUROV9QRCS5FATTT",
		"name": "Temperature by country and year",
		"group": "noaa",
		"comment": "99th percentile of avg temperature by country and year",
		"query": "SELECT\n  toStartOfYear(`date`) AS `year`,\n  quantileExact(0.99)(`tempAvg` / 10) AS `99th_avg_temp`,\n  dictGet(`country`.`country_iso_codes`, 'name', code) AS country\nFROM\n  `noaa`.`noaa_v2`\nWHERE\n  date > '1990-01-01'\n  AND code IN ('FR', 'UK', 'IN', 'NZ', 'SP', 'US')\nGROUP BY\n  year,\n  substring(station_id, 1, 2) AS code\nHAVING\n  99th_avg_temp > 0\nORDER BY\n  country,\n  year ASC\nLIMIT\n  100000;",
		"chart": {
		  "type": "line",
		  "config": {
			"xaxis": "year",
			"yaxis": "99th_avg_temp",
			"series": "country",
			"title": "Temperature by country and year"
		  }
		},
		"format": false,
		"params": []
	  },
    {
      "id": "XNHZCZZOKEPJCQYJH9IJH9",
      "name": "Recent releases",
      "group": "pypi",
      "comment": "",
      "query": "--Recently released Python packages\nWITH (\n  SELECT\n    max(upload_time) AS max_date\n  FROM\n    pypi.projects\n) AS max_date\nSELECT\n  release_month as x,\n  name as y,\n  uniqExact(version) AS z\nFROM\n  pypi.projects\nWHERE\n  (name IN { packages: Array(String) })\n  AND (\n    toStartOfMonth(upload_time) > toStartOfMonth(max_date - toIntervalMonth(6))\n  )\nGROUP BY\n  name,\n  toMonth(upload_time) AS month,\n  formatDateTime(upload_time, '%b') AS release_month\nORDER BY\n  month ASC\nLIMIT\n  30",
      "chart": {
        "type": "line"
      },
      "format": false,
      "params": [
        {
          "name": "packages",
          "type": "Array(String)",
          "textStartPos": 207,
          "textEndPos": 231,
          "value": "['boto3','urllib3','botocore','requests','setuptools']"
        }
      ]
    },
    {
      "id": "UEZEBJHYKTWDYXQZFMUT39",
      "name": "Top projects",
      "group": "pypi",
      "comment": "",
      "query": "--Most downloaded projects\nSELECT\n  project,\n  sum(count) AS c\nFROM\n  pypi.pypi_downloads\nGROUP BY\n  project\nORDER BY\n  c DESC\nLIMIT\n  5",
      "chart": {
        "type": "line"
      },
      "format": false,
      "params": []
    },
    {
      "id": "TZE9ISWDW4UMB3BYVVZTSA",
      "name": "Total downloads and projects",
      "group": "pypi",
      "comment": "",
      "query": "SELECT formatReadableQuantity(sum(count)) AS total, uniqExact(project) as projects FROM pypi.pypi_downloads",
      "chart": {
        "type": "line"
      },
      "format": false,
      "params": []
    }
	]
}
